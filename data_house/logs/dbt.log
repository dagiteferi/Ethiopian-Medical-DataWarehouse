[0m17:33:05.648203 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002830F2F5B50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002830CC60320>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002830EE91C70>]}


============================== 17:33:05.744507 | 41798b55-9029-43f5-952e-ed14197f11b2 ==============================
[0m17:33:05.744507 [info ] [MainThread]: Running with dbt=1.9.2
[0m17:33:05.746067 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\Dagi\\Documents\\KAIM\\week-7\\Ethiopian-Medical-DataWarehouse\\data_house\\logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\Dagi\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m17:33:08.250495 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '41798b55-9029-43f5-952e-ed14197f11b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002830F7694F0>]}
[0m17:33:08.350483 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '41798b55-9029-43f5-952e-ed14197f11b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002830F3D4110>]}
[0m17:33:08.352489 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m17:33:11.572344 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m17:33:11.576351 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m17:33:11.578352 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '41798b55-9029-43f5-952e-ed14197f11b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002830F7B27E0>]}
[0m17:33:20.383364 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.data_house.transform_messages' (models\example\transform_messages.sql) depends on a node named 'raw_table' which was not found
[0m17:33:20.386390 [debug] [MainThread]: Command `dbt run` failed at 17:33:20.386390 after 16.89 seconds
[0m17:33:20.387389 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002830CC60320>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002831102E060>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028310F7A030>]}
[0m17:33:20.387389 [debug] [MainThread]: Flushing usage events
[0m17:33:21.767772 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:35:00.655323 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002160F66EAE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002160EF2A7E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002160ED6E660>]}


============================== 17:35:00.666326 | c1a7de36-8aed-448c-849e-65d607d7939d ==============================
[0m17:35:00.666326 [info ] [MainThread]: Running with dbt=1.9.2
[0m17:35:00.669330 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\Dagi\\Documents\\KAIM\\week-7\\Ethiopian-Medical-DataWarehouse\\data_house\\logs', 'profiles_dir': 'C:\\Users\\Dagi\\.dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m17:35:01.207330 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c1a7de36-8aed-448c-849e-65d607d7939d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002160F914CE0>]}
[0m17:35:01.336334 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c1a7de36-8aed-448c-849e-65d607d7939d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002160FB290A0>]}
[0m17:35:01.338320 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m17:35:01.845321 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m17:35:01.847324 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m17:35:01.849323 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'c1a7de36-8aed-448c-849e-65d607d7939d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002160FAA3620>]}
[0m17:35:04.370147 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.data_house.transform_messages' (models\example\transform_messages.sql) depends on a node named 'messages_raw' which was not found
[0m17:35:04.372454 [debug] [MainThread]: Command `dbt run` failed at 17:35:04.372454 after 4.17 seconds
[0m17:35:04.373466 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002160F915490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021610F3F6B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021610F8A5A0>]}
[0m17:35:04.374465 [debug] [MainThread]: Flushing usage events
[0m17:35:05.388003 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:44:56.941591 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FA98946750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FA98946330>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FA95F98BC0>]}


============================== 17:44:57.015166 | 5e79366e-baa3-42e9-a005-2559be9ea8c0 ==============================
[0m17:44:57.015166 [info ] [MainThread]: Running with dbt=1.9.2
[0m17:44:57.017157 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Dagi\\.dbt', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\Dagi\\Documents\\KAIM\\week-7\\Ethiopian-Medical-DataWarehouse\\data_house\\logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m17:44:57.803118 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5e79366e-baa3-42e9-a005-2559be9ea8c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FA989181D0>]}
[0m17:44:57.942118 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5e79366e-baa3-42e9-a005-2559be9ea8c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FA98E2B890>]}
[0m17:44:57.945120 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m17:44:58.619116 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m17:44:58.621057 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m17:44:58.622058 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '5e79366e-baa3-42e9-a005-2559be9ea8c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FA98F6EF00>]}
[0m17:45:01.434956 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.data_house.transform_messages' (models\example\transform_messages.sql) depends on a source named 'telegram_data.telegram_messages' which was not found
[0m17:45:01.466966 [debug] [MainThread]: Command `dbt run` failed at 17:45:01.465962 after 5.45 seconds
[0m17:45:01.467965 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FA989EFAD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FA98F8E600>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FA9A42A660>]}
[0m17:45:01.469961 [debug] [MainThread]: Flushing usage events
[0m17:45:03.156943 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:48:01.900287 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022C1D5A2BA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022C205197C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022C2084F140>]}


============================== 17:48:01.979302 | b5aa021c-c8b9-4c25-86ec-d70e51747ceb ==============================
[0m17:48:01.979302 [info ] [MainThread]: Running with dbt=1.9.2
[0m17:48:01.980288 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Dagi\\.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\Dagi\\Documents\\KAIM\\week-7\\Ethiopian-Medical-DataWarehouse\\data_house\\logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m17:48:02.853306 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b5aa021c-c8b9-4c25-86ec-d70e51747ceb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022C20702C30>]}
[0m17:48:03.104909 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b5aa021c-c8b9-4c25-86ec-d70e51747ceb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022C203D5C70>]}
[0m17:48:03.107913 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m17:48:03.689712 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m17:48:03.691731 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m17:48:03.692151 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'b5aa021c-c8b9-4c25-86ec-d70e51747ceb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022C2105AF90>]}
[0m17:48:06.180106 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b5aa021c-c8b9-4c25-86ec-d70e51747ceb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022C224AC440>]}
[0m17:48:06.374690 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\manifest.json
[0m17:48:06.420292 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\semantic_manifest.json
[0m17:48:08.322140 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b5aa021c-c8b9-4c25-86ec-d70e51747ceb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022C225FBA70>]}
[0m17:48:08.323140 [info ] [MainThread]: Found 3 models, 4 data tests, 1 source, 431 macros
[0m17:48:08.325140 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b5aa021c-c8b9-4c25-86ec-d70e51747ceb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022C225FB470>]}
[0m17:48:08.328138 [info ] [MainThread]: 
[0m17:48:08.329150 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:48:08.331155 [info ] [MainThread]: 
[0m17:48:08.333152 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m17:48:08.343139 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Data_house'
[0m17:48:26.516115 [debug] [ThreadPool]: Using postgres connection "list_Data_house"
[0m17:48:26.517111 [debug] [ThreadPool]: On list_Data_house: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "connection_name": "list_Data_house"} */

    select distinct nspname from pg_namespace
  
[0m17:48:26.518111 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:48:36.111910 [debug] [ThreadPool]: Postgres adapter: Got a retryable error when attempting to open a postgres connection.
1 attempts remaining. Retrying in 0 seconds.
Error:
connection to server at "localhost" (::1), port 5432 failed: FATAL:  password authentication failed for user "postgres"

[0m17:48:36.357037 [debug] [ThreadPool]: Postgres adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "connection_name": "list_Data_house"} */

    select distinct nspname from pg_namespace
  
[0m17:48:36.358056 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m17:48:36.358056 [debug] [ThreadPool]: Postgres adapter: Error running SQL: macro list_schemas
[0m17:48:36.359054 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m17:48:36.360053 [debug] [ThreadPool]: On list_Data_house: No close available on handle
[0m17:48:36.361027 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:48:36.361027 [debug] [MainThread]: Connection 'list_Data_house' was properly closed.
[0m17:48:36.399338 [info ] [MainThread]: 
[0m17:48:36.400200 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 28.03 seconds (28.03s).
[0m17:48:36.402219 [error] [MainThread]: Encountered an error:
Database Error
  connection to server at "localhost" (::1), port 5432 failed: FATAL:  password authentication failed for user "postgres"
  
[0m17:48:36.405244 [debug] [MainThread]: Command `dbt run` failed at 17:48:36.404240 after 35.70 seconds
[0m17:48:36.405244 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022C20AD63F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022C226D96D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022C226708F0>]}
[0m17:48:36.406247 [debug] [MainThread]: Flushing usage events
[0m17:48:38.422606 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:52:43.102673 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024D3EC7BDA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024D3FE5C770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024D427AB530>]}


============================== 17:52:43.165461 | 21cc9371-710a-47cd-88d5-295dcd666af0 ==============================
[0m17:52:43.165461 [info ] [MainThread]: Running with dbt=1.9.2
[0m17:52:43.167776 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Dagi\\.dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\Dagi\\Documents\\KAIM\\week-7\\Ethiopian-Medical-DataWarehouse\\data_house\\logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m17:52:43.830965 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '21cc9371-710a-47cd-88d5-295dcd666af0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024D42E3D070>]}
[0m17:52:43.930942 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '21cc9371-710a-47cd-88d5-295dcd666af0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024D42E3D3D0>]}
[0m17:52:43.933947 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m17:52:44.602616 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m17:52:44.974776 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:52:44.975778 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:52:45.043774 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '21cc9371-710a-47cd-88d5-295dcd666af0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024D42F30770>]}
[0m17:52:45.258770 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\manifest.json
[0m17:52:45.282774 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\semantic_manifest.json
[0m17:52:46.374456 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '21cc9371-710a-47cd-88d5-295dcd666af0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024D44277680>]}
[0m17:52:46.376462 [info ] [MainThread]: Found 3 models, 4 data tests, 1 source, 431 macros
[0m17:52:46.378453 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '21cc9371-710a-47cd-88d5-295dcd666af0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024D44230200>]}
[0m17:52:46.383450 [info ] [MainThread]: 
[0m17:52:46.384458 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:52:46.418454 [info ] [MainThread]: 
[0m17:52:46.425455 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m17:52:46.459463 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Data_house'
[0m17:52:47.649757 [debug] [ThreadPool]: Using postgres connection "list_Data_house"
[0m17:52:47.652762 [debug] [ThreadPool]: On list_Data_house: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "connection_name": "list_Data_house"} */

    select distinct nspname from pg_namespace
  
[0m17:52:47.654765 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:52:50.376614 [debug] [ThreadPool]: SQL status: SELECT 4 in 2.722 seconds
[0m17:52:50.383619 [debug] [ThreadPool]: On list_Data_house: Close
[0m17:52:50.387576 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_Data_house, now create_Data_house_analytics)
[0m17:52:50.390576 [debug] [ThreadPool]: Creating schema "database: "Data_house"
schema: "analytics"
"
[0m17:52:50.409573 [debug] [ThreadPool]: Using postgres connection "create_Data_house_analytics"
[0m17:52:50.410575 [debug] [ThreadPool]: On create_Data_house_analytics: BEGIN
[0m17:52:50.411575 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:52:50.670036 [debug] [ThreadPool]: SQL status: BEGIN in 0.258 seconds
[0m17:52:50.671034 [debug] [ThreadPool]: Using postgres connection "create_Data_house_analytics"
[0m17:52:50.671034 [debug] [ThreadPool]: On create_Data_house_analytics: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "connection_name": "create_Data_house_analytics"} */
create schema if not exists "analytics"
[0m17:52:50.986963 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.315 seconds
[0m17:52:50.989994 [debug] [ThreadPool]: On create_Data_house_analytics: COMMIT
[0m17:52:50.991995 [debug] [ThreadPool]: Using postgres connection "create_Data_house_analytics"
[0m17:52:50.992994 [debug] [ThreadPool]: On create_Data_house_analytics: COMMIT
[0m17:52:51.061423 [debug] [ThreadPool]: SQL status: COMMIT in 0.067 seconds
[0m17:52:51.062444 [debug] [ThreadPool]: On create_Data_house_analytics: Close
[0m17:52:51.067467 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Data_house_analytics'
[0m17:52:51.090485 [debug] [ThreadPool]: Using postgres connection "list_Data_house_analytics"
[0m17:52:51.092463 [debug] [ThreadPool]: On list_Data_house_analytics: BEGIN
[0m17:52:51.093463 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:52:51.290406 [debug] [ThreadPool]: SQL status: BEGIN in 0.197 seconds
[0m17:52:51.291409 [debug] [ThreadPool]: Using postgres connection "list_Data_house_analytics"
[0m17:52:51.291409 [debug] [ThreadPool]: On list_Data_house_analytics: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "connection_name": "list_Data_house_analytics"} */
select
      'Data_house' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'Data_house' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'Data_house' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m17:52:51.962395 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.670 seconds
[0m17:52:51.968445 [debug] [ThreadPool]: On list_Data_house_analytics: ROLLBACK
[0m17:52:51.970400 [debug] [ThreadPool]: On list_Data_house_analytics: Close
[0m17:52:51.993445 [debug] [MainThread]: Using postgres connection "master"
[0m17:52:51.995422 [debug] [MainThread]: On master: BEGIN
[0m17:52:51.995422 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:52:52.099158 [debug] [MainThread]: SQL status: BEGIN in 0.103 seconds
[0m17:52:52.100183 [debug] [MainThread]: Using postgres connection "master"
[0m17:52:52.100183 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m17:52:52.400074 [debug] [MainThread]: SQL status: SELECT 0 in 0.298 seconds
[0m17:52:52.406070 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '21cc9371-710a-47cd-88d5-295dcd666af0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024D42EBECF0>]}
[0m17:52:52.408070 [debug] [MainThread]: On master: ROLLBACK
[0m17:52:52.411076 [debug] [MainThread]: Using postgres connection "master"
[0m17:52:52.412072 [debug] [MainThread]: On master: BEGIN
[0m17:52:52.416125 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m17:52:52.419065 [debug] [MainThread]: On master: COMMIT
[0m17:52:52.422117 [debug] [MainThread]: Using postgres connection "master"
[0m17:52:52.424116 [debug] [MainThread]: On master: COMMIT
[0m17:52:52.426092 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m17:52:52.428117 [debug] [MainThread]: On master: Close
[0m17:52:52.463566 [debug] [Thread-1 (]: Began running node model.data_house.my_first_dbt_model
[0m17:52:52.464566 [info ] [Thread-1 (]: 1 of 3 START sql table model analytics.my_first_dbt_model ...................... [RUN]
[0m17:52:52.467257 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.data_house.my_first_dbt_model'
[0m17:52:52.468279 [debug] [Thread-1 (]: Began compiling node model.data_house.my_first_dbt_model
[0m17:52:52.497253 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_house.my_first_dbt_model"
[0m17:52:52.531729 [debug] [Thread-1 (]: Began executing node model.data_house.my_first_dbt_model
[0m17:52:52.597726 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_house.my_first_dbt_model"
[0m17:52:52.633728 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m17:52:52.633728 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: BEGIN
[0m17:52:52.634728 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:52:52.694682 [debug] [Thread-1 (]: SQL status: BEGIN in 0.060 seconds
[0m17:52:52.695688 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m17:52:52.696685 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_first_dbt_model"} */

  
    

  create  table "Data_house"."analytics"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m17:52:53.232053 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.534 seconds
[0m17:52:53.242938 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m17:52:53.243939 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_first_dbt_model"} */
alter table "Data_house"."analytics"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m17:52:53.258103 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.014 seconds
[0m17:52:53.288126 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: COMMIT
[0m17:52:53.289127 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m17:52:53.290126 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: COMMIT
[0m17:52:53.292342 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m17:52:53.310360 [debug] [Thread-1 (]: Applying DROP to: "Data_house"."analytics"."my_first_dbt_model__dbt_backup"
[0m17:52:53.318359 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m17:52:53.319366 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_first_dbt_model"} */
drop table if exists "Data_house"."analytics"."my_first_dbt_model__dbt_backup" cascade
[0m17:52:53.320539 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m17:52:53.323592 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: Close
[0m17:52:53.329571 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '21cc9371-710a-47cd-88d5-295dcd666af0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024D4002E390>]}
[0m17:52:53.331569 [info ] [Thread-1 (]: 1 of 3 OK created sql table model analytics.my_first_dbt_model ................. [[32mSELECT 2[0m in 0.86s]
[0m17:52:53.333568 [debug] [Thread-1 (]: Finished running node model.data_house.my_first_dbt_model
[0m17:52:53.333568 [debug] [Thread-1 (]: Began running node model.data_house.transform_messages
[0m17:52:53.334565 [info ] [Thread-1 (]: 2 of 3 START sql view model analytics.transform_messages ....................... [RUN]
[0m17:52:53.336571 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_house.my_first_dbt_model, now model.data_house.transform_messages)
[0m17:52:53.337595 [debug] [Thread-1 (]: Began compiling node model.data_house.transform_messages
[0m17:52:53.341591 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_house.transform_messages"
[0m17:52:53.344568 [debug] [Thread-1 (]: Began executing node model.data_house.transform_messages
[0m17:52:53.383573 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_house.transform_messages"
[0m17:52:53.386571 [debug] [Thread-1 (]: Using postgres connection "model.data_house.transform_messages"
[0m17:52:53.388585 [debug] [Thread-1 (]: On model.data_house.transform_messages: BEGIN
[0m17:52:53.389568 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:52:53.563873 [debug] [Thread-1 (]: SQL status: BEGIN in 0.175 seconds
[0m17:52:53.564880 [debug] [Thread-1 (]: Using postgres connection "model.data_house.transform_messages"
[0m17:52:53.565878 [debug] [Thread-1 (]: On model.data_house.transform_messages: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.transform_messages"} */

  create view "Data_house"."analytics"."transform_messages__dbt_tmp"
    
    
  as (
    with cleaned_data as (
    select
        id,
        channel_title,
        channel_username,
        message_id,
        message,
        message_date,
        media_path,
        emoji_used,
        youtube_links,
        case 
            when emoji_used = 'No emoji' then false
            else true
        end as has_emoji,
        case 
            when youtube_links = 'No YouTube link' then false
            else true
        end as has_youtube_links
    from "Data_house"."telegram_data"."telegram_messages"
)

select
    *,
    current_timestamp as transformed_at
from cleaned_data
  );
[0m17:52:53.635370 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "telegram_data.telegram_messages" does not exist
LINE 26:     from "Data_house"."telegram_data"."telegram_messages"
                  ^

[0m17:52:53.637324 [debug] [Thread-1 (]: On model.data_house.transform_messages: ROLLBACK
[0m17:52:53.640365 [debug] [Thread-1 (]: On model.data_house.transform_messages: Close
[0m17:52:56.868909 [debug] [Thread-1 (]: Database Error in model transform_messages (models\example\transform_messages.sql)
  relation "telegram_data.telegram_messages" does not exist
  LINE 26:     from "Data_house"."telegram_data"."telegram_messages"
                    ^
  compiled code at target\run\data_house\models\example\transform_messages.sql
[0m17:52:56.869914 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '21cc9371-710a-47cd-88d5-295dcd666af0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024D44562AB0>]}
[0m17:52:56.870938 [error] [Thread-1 (]: 2 of 3 ERROR creating sql view model analytics.transform_messages .............. [[31mERROR[0m in 3.53s]
[0m17:52:56.872913 [debug] [Thread-1 (]: Finished running node model.data_house.transform_messages
[0m17:52:56.872913 [debug] [Thread-1 (]: Began running node model.data_house.my_second_dbt_model
[0m17:52:56.873910 [debug] [Thread-4 (]: Marking all children of 'model.data_house.transform_messages' to be skipped because of status 'error'.  Reason: Database Error in model transform_messages (models\example\transform_messages.sql)
  relation "telegram_data.telegram_messages" does not exist
  LINE 26:     from "Data_house"."telegram_data"."telegram_messages"
                    ^
  compiled code at target\run\data_house\models\example\transform_messages.sql.
[0m17:52:56.874932 [info ] [Thread-1 (]: 3 of 3 START sql view model analytics.my_second_dbt_model ...................... [RUN]
[0m17:52:56.877915 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_house.transform_messages, now model.data_house.my_second_dbt_model)
[0m17:52:56.878922 [debug] [Thread-1 (]: Began compiling node model.data_house.my_second_dbt_model
[0m17:52:56.885913 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_house.my_second_dbt_model"
[0m17:52:56.892918 [debug] [Thread-1 (]: Began executing node model.data_house.my_second_dbt_model
[0m17:52:56.900914 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_house.my_second_dbt_model"
[0m17:52:56.939519 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m17:52:56.940547 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: BEGIN
[0m17:52:56.941526 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:52:57.024518 [debug] [Thread-1 (]: SQL status: BEGIN in 0.083 seconds
[0m17:52:57.025521 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m17:52:57.026520 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_second_dbt_model"} */

  create view "Data_house"."analytics"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "Data_house"."analytics"."my_first_dbt_model"
where id = 1
  );
[0m17:52:57.123657 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.096 seconds
[0m17:52:57.127655 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m17:52:57.128655 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_second_dbt_model"} */
alter table "Data_house"."analytics"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m17:52:57.129656 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:52:57.132655 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: COMMIT
[0m17:52:57.133655 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m17:52:57.133655 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: COMMIT
[0m17:52:57.136659 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m17:52:57.140654 [debug] [Thread-1 (]: Applying DROP to: "Data_house"."analytics"."my_second_dbt_model__dbt_backup"
[0m17:52:57.144655 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m17:52:57.145656 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_second_dbt_model"} */
drop view if exists "Data_house"."analytics"."my_second_dbt_model__dbt_backup" cascade
[0m17:52:57.146661 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.000 seconds
[0m17:52:57.148656 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: Close
[0m17:52:57.149656 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '21cc9371-710a-47cd-88d5-295dcd666af0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024D442DCF50>]}
[0m17:52:57.151661 [info ] [Thread-1 (]: 3 of 3 OK created sql view model analytics.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.27s]
[0m17:52:57.154665 [debug] [Thread-1 (]: Finished running node model.data_house.my_second_dbt_model
[0m17:52:57.157656 [debug] [MainThread]: Using postgres connection "master"
[0m17:52:57.158656 [debug] [MainThread]: On master: BEGIN
[0m17:52:57.158656 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:52:57.228657 [debug] [MainThread]: SQL status: BEGIN in 0.070 seconds
[0m17:52:57.229656 [debug] [MainThread]: On master: COMMIT
[0m17:52:57.230678 [debug] [MainThread]: Using postgres connection "master"
[0m17:52:57.230678 [debug] [MainThread]: On master: COMMIT
[0m17:52:57.231680 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m17:52:57.231680 [debug] [MainThread]: On master: Close
[0m17:52:57.232681 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:52:57.233659 [debug] [MainThread]: Connection 'create_Data_house_analytics' was properly closed.
[0m17:52:57.234662 [debug] [MainThread]: Connection 'list_Data_house_analytics' was properly closed.
[0m17:52:57.236662 [debug] [MainThread]: Connection 'model.data_house.my_second_dbt_model' was properly closed.
[0m17:52:57.237665 [info ] [MainThread]: 
[0m17:52:57.238660 [info ] [MainThread]: Finished running 1 table model, 2 view models in 0 hours 0 minutes and 10.81 seconds (10.81s).
[0m17:52:57.241656 [debug] [MainThread]: Command end result
[0m17:52:57.311658 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\manifest.json
[0m17:52:57.314660 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\semantic_manifest.json
[0m17:52:57.326658 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\run_results.json
[0m17:52:57.327661 [info ] [MainThread]: 
[0m17:52:57.329658 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m17:52:57.330658 [info ] [MainThread]: 
[0m17:52:57.331659 [error] [MainThread]:   Database Error in model transform_messages (models\example\transform_messages.sql)
  relation "telegram_data.telegram_messages" does not exist
  LINE 26:     from "Data_house"."telegram_data"."telegram_messages"
                    ^
  compiled code at target\run\data_house\models\example\transform_messages.sql
[0m17:52:57.334661 [info ] [MainThread]: 
[0m17:52:57.336673 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
[0m17:52:57.340669 [debug] [MainThread]: Command `dbt run` failed at 17:52:57.339667 after 15.91 seconds
[0m17:52:57.342666 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024D44267620>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024D42C7D310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024D42C7D400>]}
[0m17:52:57.343659 [debug] [MainThread]: Flushing usage events
[0m17:52:58.664347 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:55:23.249128 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025811EB94F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002580FB9EC90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002581280C170>]}


============================== 17:55:23.256129 | b0894ca8-707a-487d-bb94-32686242d74a ==============================
[0m17:55:23.256129 [info ] [MainThread]: Running with dbt=1.9.2
[0m17:55:23.257120 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\Dagi\\Documents\\KAIM\\week-7\\Ethiopian-Medical-DataWarehouse\\data_house\\logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\Dagi\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m17:55:23.597147 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b0894ca8-707a-487d-bb94-32686242d74a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258129327E0>]}
[0m17:55:23.692144 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b0894ca8-707a-487d-bb94-32686242d74a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258122F73E0>]}
[0m17:55:23.694143 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m17:55:24.056118 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m17:55:24.343117 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m17:55:24.344145 [debug] [MainThread]: Partial parsing: updated file: data_house://models\example\transform_messages.sql
[0m17:55:24.851120 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b0894ca8-707a-487d-bb94-32686242d74a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002581403FE00>]}
[0m17:55:24.996104 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\manifest.json
[0m17:55:25.002101 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\semantic_manifest.json
[0m17:55:25.055409 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b0894ca8-707a-487d-bb94-32686242d74a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025814056A20>]}
[0m17:55:25.056399 [info ] [MainThread]: Found 3 models, 4 data tests, 1 source, 431 macros
[0m17:55:25.058398 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b0894ca8-707a-487d-bb94-32686242d74a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025813E06030>]}
[0m17:55:25.060395 [info ] [MainThread]: 
[0m17:55:25.061767 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:55:25.063788 [info ] [MainThread]: 
[0m17:55:25.065798 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m17:55:25.072786 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Data_house'
[0m17:55:25.222791 [debug] [ThreadPool]: Using postgres connection "list_Data_house"
[0m17:55:25.223790 [debug] [ThreadPool]: On list_Data_house: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "connection_name": "list_Data_house"} */

    select distinct nspname from pg_namespace
  
[0m17:55:25.224789 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:55:25.299791 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.075 seconds
[0m17:55:25.301785 [debug] [ThreadPool]: On list_Data_house: Close
[0m17:55:25.303788 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Data_house_analytics'
[0m17:55:25.313807 [debug] [ThreadPool]: Using postgres connection "list_Data_house_analytics"
[0m17:55:25.313807 [debug] [ThreadPool]: On list_Data_house_analytics: BEGIN
[0m17:55:25.314808 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:55:25.377790 [debug] [ThreadPool]: SQL status: BEGIN in 0.063 seconds
[0m17:55:25.378791 [debug] [ThreadPool]: Using postgres connection "list_Data_house_analytics"
[0m17:55:25.379792 [debug] [ThreadPool]: On list_Data_house_analytics: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "connection_name": "list_Data_house_analytics"} */
select
      'Data_house' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'Data_house' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'Data_house' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m17:55:25.390789 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.011 seconds
[0m17:55:25.392823 [debug] [ThreadPool]: On list_Data_house_analytics: ROLLBACK
[0m17:55:25.393806 [debug] [ThreadPool]: On list_Data_house_analytics: Close
[0m17:55:25.403785 [debug] [MainThread]: Using postgres connection "master"
[0m17:55:25.403785 [debug] [MainThread]: On master: BEGIN
[0m17:55:25.404785 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:55:25.467787 [debug] [MainThread]: SQL status: BEGIN in 0.063 seconds
[0m17:55:25.467787 [debug] [MainThread]: Using postgres connection "master"
[0m17:55:25.468806 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m17:55:25.505786 [debug] [MainThread]: SQL status: SELECT 1 in 0.036 seconds
[0m17:55:25.507805 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b0894ca8-707a-487d-bb94-32686242d74a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002580FD50770>]}
[0m17:55:25.508805 [debug] [MainThread]: On master: ROLLBACK
[0m17:55:25.509787 [debug] [MainThread]: Using postgres connection "master"
[0m17:55:25.509787 [debug] [MainThread]: On master: BEGIN
[0m17:55:25.510810 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m17:55:25.511811 [debug] [MainThread]: On master: COMMIT
[0m17:55:25.512793 [debug] [MainThread]: Using postgres connection "master"
[0m17:55:25.513792 [debug] [MainThread]: On master: COMMIT
[0m17:55:25.513792 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m17:55:25.514792 [debug] [MainThread]: On master: Close
[0m17:55:25.518791 [debug] [Thread-1 (]: Began running node model.data_house.my_first_dbt_model
[0m17:55:25.519788 [info ] [Thread-1 (]: 1 of 3 START sql table model analytics.my_first_dbt_model ...................... [RUN]
[0m17:55:25.520785 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.data_house.my_first_dbt_model'
[0m17:55:25.521789 [debug] [Thread-1 (]: Began compiling node model.data_house.my_first_dbt_model
[0m17:55:25.534788 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_house.my_first_dbt_model"
[0m17:55:25.536813 [debug] [Thread-1 (]: Began executing node model.data_house.my_first_dbt_model
[0m17:55:25.608782 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_house.my_first_dbt_model"
[0m17:55:25.610786 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m17:55:25.611786 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: BEGIN
[0m17:55:25.612791 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:55:25.673796 [debug] [Thread-1 (]: SQL status: BEGIN in 0.062 seconds
[0m17:55:25.674809 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m17:55:25.675805 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_first_dbt_model"} */

  
    

  create  table "Data_house"."analytics"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m17:55:25.686784 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.010 seconds
[0m17:55:25.696812 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m17:55:25.697811 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_first_dbt_model"} */
alter table "Data_house"."analytics"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m17:55:25.698784 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:55:25.703808 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m17:55:25.703808 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_first_dbt_model"} */
alter table "Data_house"."analytics"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m17:55:25.705785 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:55:25.738788 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: COMMIT
[0m17:55:25.739790 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m17:55:25.740790 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: COMMIT
[0m17:55:25.742797 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m17:55:25.753809 [debug] [Thread-1 (]: Applying DROP to: "Data_house"."analytics"."my_first_dbt_model__dbt_backup"
[0m17:55:25.761809 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m17:55:25.762804 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_first_dbt_model"} */
drop table if exists "Data_house"."analytics"."my_first_dbt_model__dbt_backup" cascade
[0m17:55:25.950145 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.186 seconds
[0m17:55:25.958134 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: Close
[0m17:55:25.967134 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0894ca8-707a-487d-bb94-32686242d74a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002580FC9E9C0>]}
[0m17:55:25.971165 [info ] [Thread-1 (]: 1 of 3 OK created sql table model analytics.my_first_dbt_model ................. [[32mSELECT 2[0m in 0.44s]
[0m17:55:25.975165 [debug] [Thread-1 (]: Finished running node model.data_house.my_first_dbt_model
[0m17:55:25.976165 [debug] [Thread-1 (]: Began running node model.data_house.transform_messages
[0m17:55:25.978165 [info ] [Thread-1 (]: 2 of 3 START sql view model analytics.transform_messages ....................... [RUN]
[0m17:55:25.981139 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_house.my_first_dbt_model, now model.data_house.transform_messages)
[0m17:55:25.983172 [debug] [Thread-1 (]: Began compiling node model.data_house.transform_messages
[0m17:55:25.991156 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_house.transform_messages"
[0m17:55:25.993137 [debug] [Thread-1 (]: Began executing node model.data_house.transform_messages
[0m17:55:26.038130 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_house.transform_messages"
[0m17:55:26.040132 [debug] [Thread-1 (]: Using postgres connection "model.data_house.transform_messages"
[0m17:55:26.041136 [debug] [Thread-1 (]: On model.data_house.transform_messages: BEGIN
[0m17:55:26.042131 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:55:26.108132 [debug] [Thread-1 (]: SQL status: BEGIN in 0.066 seconds
[0m17:55:26.108132 [debug] [Thread-1 (]: Using postgres connection "model.data_house.transform_messages"
[0m17:55:26.109128 [debug] [Thread-1 (]: On model.data_house.transform_messages: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.transform_messages"} */

  create view "Data_house"."analytics"."transform_messages__dbt_tmp"
    
    
  as (
    -- models/example/transform_messages.sql

with cleaned_data as (
    select
        id,
        channel_title,
        channel_username,
        message_id,
        message,
        message_date,
        media_path,
        emoji_used,
        youtube_links,
        case 
            when emoji_used = 'No emoji' then false
            else true
        end as has_emoji,
        case 
            when youtube_links = 'No YouTube link' then false
            else true
        end as has_youtube_links
    from "Data_house"."telegram_data"."telegram_messages"
)

select
    *,
    current_timestamp as transformed_at
from cleaned_data
  );
[0m17:55:26.111133 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "telegram_data.telegram_messages" does not exist
LINE 28:     from "Data_house"."telegram_data"."telegram_messages"
                  ^

[0m17:55:26.111133 [debug] [Thread-1 (]: On model.data_house.transform_messages: ROLLBACK
[0m17:55:26.112134 [debug] [Thread-1 (]: On model.data_house.transform_messages: Close
[0m17:55:26.121131 [debug] [Thread-1 (]: Database Error in model transform_messages (models\example\transform_messages.sql)
  relation "telegram_data.telegram_messages" does not exist
  LINE 28:     from "Data_house"."telegram_data"."telegram_messages"
                    ^
  compiled code at target\run\data_house\models\example\transform_messages.sql
[0m17:55:26.122131 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0894ca8-707a-487d-bb94-32686242d74a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258144F8170>]}
[0m17:55:26.123134 [error] [Thread-1 (]: 2 of 3 ERROR creating sql view model analytics.transform_messages .............. [[31mERROR[0m in 0.14s]
[0m17:55:26.125133 [debug] [Thread-1 (]: Finished running node model.data_house.transform_messages
[0m17:55:26.125133 [debug] [Thread-1 (]: Began running node model.data_house.my_second_dbt_model
[0m17:55:26.126130 [debug] [Thread-4 (]: Marking all children of 'model.data_house.transform_messages' to be skipped because of status 'error'.  Reason: Database Error in model transform_messages (models\example\transform_messages.sql)
  relation "telegram_data.telegram_messages" does not exist
  LINE 28:     from "Data_house"."telegram_data"."telegram_messages"
                    ^
  compiled code at target\run\data_house\models\example\transform_messages.sql.
[0m17:55:26.127129 [info ] [Thread-1 (]: 3 of 3 START sql view model analytics.my_second_dbt_model ...................... [RUN]
[0m17:55:26.130139 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_house.transform_messages, now model.data_house.my_second_dbt_model)
[0m17:55:26.132141 [debug] [Thread-1 (]: Began compiling node model.data_house.my_second_dbt_model
[0m17:55:26.141172 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_house.my_second_dbt_model"
[0m17:55:26.143132 [debug] [Thread-1 (]: Began executing node model.data_house.my_second_dbt_model
[0m17:55:26.152129 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_house.my_second_dbt_model"
[0m17:55:26.153132 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m17:55:26.155133 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: BEGIN
[0m17:55:26.156132 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:55:26.235132 [debug] [Thread-1 (]: SQL status: BEGIN in 0.079 seconds
[0m17:55:26.235132 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m17:55:26.236128 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_second_dbt_model"} */

  create view "Data_house"."analytics"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "Data_house"."analytics"."my_first_dbt_model"
where id = 1
  );
[0m17:55:26.246137 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.009 seconds
[0m17:55:26.250131 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m17:55:26.251132 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_second_dbt_model"} */
alter table "Data_house"."analytics"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m17:55:26.252133 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:55:26.255132 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: COMMIT
[0m17:55:26.256133 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m17:55:26.256133 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: COMMIT
[0m17:55:26.258131 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m17:55:26.263135 [debug] [Thread-1 (]: Applying DROP to: "Data_house"."analytics"."my_second_dbt_model__dbt_backup"
[0m17:55:26.268128 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m17:55:26.269130 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_second_dbt_model"} */
drop view if exists "Data_house"."analytics"."my_second_dbt_model__dbt_backup" cascade
[0m17:55:26.270131 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.000 seconds
[0m17:55:26.272128 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: Close
[0m17:55:26.273128 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0894ca8-707a-487d-bb94-32686242d74a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002581449C080>]}
[0m17:55:26.275132 [info ] [Thread-1 (]: 3 of 3 OK created sql view model analytics.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.14s]
[0m17:55:26.278130 [debug] [Thread-1 (]: Finished running node model.data_house.my_second_dbt_model
[0m17:55:26.281130 [debug] [MainThread]: Using postgres connection "master"
[0m17:55:26.282129 [debug] [MainThread]: On master: BEGIN
[0m17:55:26.283134 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:55:26.357130 [debug] [MainThread]: SQL status: BEGIN in 0.074 seconds
[0m17:55:26.358136 [debug] [MainThread]: On master: COMMIT
[0m17:55:26.359134 [debug] [MainThread]: Using postgres connection "master"
[0m17:55:26.359134 [debug] [MainThread]: On master: COMMIT
[0m17:55:26.360134 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m17:55:26.361137 [debug] [MainThread]: On master: Close
[0m17:55:26.362137 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:55:26.363138 [debug] [MainThread]: Connection 'list_Data_house' was properly closed.
[0m17:55:26.363138 [debug] [MainThread]: Connection 'list_Data_house_analytics' was properly closed.
[0m17:55:26.364134 [debug] [MainThread]: Connection 'model.data_house.my_second_dbt_model' was properly closed.
[0m17:55:26.365133 [info ] [MainThread]: 
[0m17:55:26.367133 [info ] [MainThread]: Finished running 1 table model, 2 view models in 0 hours 0 minutes and 1.30 seconds (1.30s).
[0m17:55:26.371129 [debug] [MainThread]: Command end result
[0m17:55:26.425132 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\manifest.json
[0m17:55:26.429138 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\semantic_manifest.json
[0m17:55:26.470145 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\run_results.json
[0m17:55:26.471133 [info ] [MainThread]: 
[0m17:55:26.472132 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m17:55:26.473133 [info ] [MainThread]: 
[0m17:55:26.475135 [error] [MainThread]:   Database Error in model transform_messages (models\example\transform_messages.sql)
  relation "telegram_data.telegram_messages" does not exist
  LINE 28:     from "Data_house"."telegram_data"."telegram_messages"
                    ^
  compiled code at target\run\data_house\models\example\transform_messages.sql
[0m17:55:26.477136 [info ] [MainThread]: 
[0m17:55:26.479134 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
[0m17:55:26.483138 [debug] [MainThread]: Command `dbt run` failed at 17:55:26.482157 after 3.52 seconds
[0m17:55:26.484165 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258126706E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025811CD1970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025811CD1280>]}
[0m17:55:26.485157 [debug] [MainThread]: Flushing usage events
[0m17:55:27.416786 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:58:25.973935 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000281B3012900>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000281B584F6E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000281B584FC80>]}


============================== 17:58:26.071848 | b4ea7647-1305-4379-b43c-23d4b0fa2d8a ==============================
[0m17:58:26.071848 [info ] [MainThread]: Running with dbt=1.9.2
[0m17:58:26.073850 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Dagi\\.dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\Dagi\\Documents\\KAIM\\week-7\\Ethiopian-Medical-DataWarehouse\\data_house\\logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt run', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m17:58:27.346411 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b4ea7647-1305-4379-b43c-23d4b0fa2d8a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000281B5DC82C0>]}
[0m17:58:27.441366 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b4ea7647-1305-4379-b43c-23d4b0fa2d8a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000281B31C03E0>]}
[0m17:58:27.443369 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m17:58:28.296315 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m17:58:29.725954 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:58:29.726954 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:58:29.796953 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b4ea7647-1305-4379-b43c-23d4b0fa2d8a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000281B5EFEF90>]}
[0m17:58:30.015952 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\manifest.json
[0m17:58:30.119950 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\semantic_manifest.json
[0m17:58:31.524444 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b4ea7647-1305-4379-b43c-23d4b0fa2d8a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000281B7353AD0>]}
[0m17:58:31.525441 [info ] [MainThread]: Found 3 models, 4 data tests, 1 source, 431 macros
[0m17:58:31.527445 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b4ea7647-1305-4379-b43c-23d4b0fa2d8a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000281B731D070>]}
[0m17:58:31.534447 [info ] [MainThread]: 
[0m17:58:31.536443 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:58:31.579440 [info ] [MainThread]: 
[0m17:58:31.593444 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m17:58:31.628445 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Data_house'
[0m17:58:32.920805 [debug] [ThreadPool]: Using postgres connection "list_Data_house"
[0m17:58:32.922800 [debug] [ThreadPool]: On list_Data_house: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "connection_name": "list_Data_house"} */

    select distinct nspname from pg_namespace
  
[0m17:58:32.924804 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:58:35.146528 [debug] [ThreadPool]: SQL status: SELECT 5 in 2.221 seconds
[0m17:58:35.150526 [debug] [ThreadPool]: On list_Data_house: Close
[0m17:58:35.154531 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Data_house_analytics'
[0m17:58:35.172534 [debug] [ThreadPool]: Using postgres connection "list_Data_house_analytics"
[0m17:58:35.174532 [debug] [ThreadPool]: On list_Data_house_analytics: BEGIN
[0m17:58:35.176526 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:58:35.264195 [debug] [ThreadPool]: SQL status: BEGIN in 0.087 seconds
[0m17:58:35.264195 [debug] [ThreadPool]: Using postgres connection "list_Data_house_analytics"
[0m17:58:35.265196 [debug] [ThreadPool]: On list_Data_house_analytics: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "connection_name": "list_Data_house_analytics"} */
select
      'Data_house' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'Data_house' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'Data_house' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m17:58:35.364278 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.099 seconds
[0m17:58:35.370281 [debug] [ThreadPool]: On list_Data_house_analytics: ROLLBACK
[0m17:58:35.373305 [debug] [ThreadPool]: On list_Data_house_analytics: Close
[0m17:58:35.390268 [debug] [MainThread]: Using postgres connection "master"
[0m17:58:35.391263 [debug] [MainThread]: On master: BEGIN
[0m17:58:35.392268 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:58:35.455974 [debug] [MainThread]: SQL status: BEGIN in 0.064 seconds
[0m17:58:35.456982 [debug] [MainThread]: Using postgres connection "master"
[0m17:58:35.457978 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m17:58:35.712820 [debug] [MainThread]: SQL status: SELECT 1 in 0.254 seconds
[0m17:58:35.727828 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b4ea7647-1305-4379-b43c-23d4b0fa2d8a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000281B5F7EFC0>]}
[0m17:58:35.731826 [debug] [MainThread]: On master: ROLLBACK
[0m17:58:35.734813 [debug] [MainThread]: Using postgres connection "master"
[0m17:58:35.736810 [debug] [MainThread]: On master: BEGIN
[0m17:58:35.738808 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m17:58:35.739813 [debug] [MainThread]: On master: COMMIT
[0m17:58:35.739813 [debug] [MainThread]: Using postgres connection "master"
[0m17:58:35.740809 [debug] [MainThread]: On master: COMMIT
[0m17:58:35.741809 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m17:58:35.742816 [debug] [MainThread]: On master: Close
[0m17:58:35.800809 [debug] [Thread-1 (]: Began running node model.data_house.my_first_dbt_model
[0m17:58:35.801811 [info ] [Thread-1 (]: 1 of 3 START sql table model analytics.my_first_dbt_model ...................... [RUN]
[0m17:58:35.803817 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.data_house.my_first_dbt_model'
[0m17:58:35.804829 [debug] [Thread-1 (]: Began compiling node model.data_house.my_first_dbt_model
[0m17:58:35.814455 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_house.my_first_dbt_model"
[0m17:58:35.816459 [debug] [Thread-1 (]: Began executing node model.data_house.my_first_dbt_model
[0m17:58:35.878071 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_house.my_first_dbt_model"
[0m17:58:35.880072 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m17:58:35.881072 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: BEGIN
[0m17:58:35.881072 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m17:58:35.943092 [debug] [Thread-1 (]: SQL status: BEGIN in 0.062 seconds
[0m17:58:35.944075 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m17:58:35.945072 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_first_dbt_model"} */

  
    

  create  table "Data_house"."analytics"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m17:58:36.337430 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.392 seconds
[0m17:58:36.351425 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m17:58:36.353428 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_first_dbt_model"} */
alter table "Data_house"."analytics"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m17:58:36.693846 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.307 seconds
[0m17:58:36.701844 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m17:58:36.706843 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_first_dbt_model"} */
alter table "Data_house"."analytics"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m17:58:36.709849 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:58:36.797853 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: COMMIT
[0m17:58:36.799851 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m17:58:36.800851 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: COMMIT
[0m17:58:36.809848 [debug] [Thread-1 (]: SQL status: COMMIT in 0.008 seconds
[0m17:58:36.831852 [debug] [Thread-1 (]: Applying DROP to: "Data_house"."analytics"."my_first_dbt_model__dbt_backup"
[0m17:58:36.855847 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m17:58:36.856848 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_first_dbt_model"} */
drop table if exists "Data_house"."analytics"."my_first_dbt_model__dbt_backup" cascade
[0m17:58:37.245648 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.386 seconds
[0m17:58:37.250659 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: Close
[0m17:58:37.322645 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b4ea7647-1305-4379-b43c-23d4b0fa2d8a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000281B7AE8560>]}
[0m17:58:37.324646 [info ] [Thread-1 (]: 1 of 3 OK created sql table model analytics.my_first_dbt_model ................. [[32mSELECT 2[0m in 1.45s]
[0m17:58:37.328638 [debug] [Thread-1 (]: Finished running node model.data_house.my_first_dbt_model
[0m17:58:37.329646 [debug] [Thread-1 (]: Began running node model.data_house.transform_messages
[0m17:58:37.331662 [info ] [Thread-1 (]: 2 of 3 START sql view model analytics.transform_messages ....................... [RUN]
[0m17:58:37.333648 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_house.my_first_dbt_model, now model.data_house.transform_messages)
[0m17:58:37.334648 [debug] [Thread-1 (]: Began compiling node model.data_house.transform_messages
[0m17:58:37.345665 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_house.transform_messages"
[0m17:58:37.348641 [debug] [Thread-1 (]: Began executing node model.data_house.transform_messages
[0m17:58:37.396635 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_house.transform_messages"
[0m17:58:37.398644 [debug] [Thread-1 (]: Using postgres connection "model.data_house.transform_messages"
[0m17:58:37.399640 [debug] [Thread-1 (]: On model.data_house.transform_messages: BEGIN
[0m17:58:37.400638 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:58:37.462658 [debug] [Thread-1 (]: SQL status: BEGIN in 0.062 seconds
[0m17:58:37.463640 [debug] [Thread-1 (]: Using postgres connection "model.data_house.transform_messages"
[0m17:58:37.464636 [debug] [Thread-1 (]: On model.data_house.transform_messages: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.transform_messages"} */

  create view "Data_house"."analytics"."transform_messages__dbt_tmp"
    
    
  as (
    -- models/example/transform_messages.sql

with cleaned_data as (
    select
        id,
        channel_title,
        channel_username,
        message_id,
        message,
        message_date,
        media_path,
        emoji_used,
        youtube_links,
        case 
            when emoji_used = 'No emoji' then false
            else true
        end as has_emoji,
        case 
            when youtube_links = 'No YouTube link' then false
            else true
        end as has_youtube_links
    from "Data_house"."telegram_data"."telegram_messages"
)

select
    *,
    current_timestamp as transformed_at
from cleaned_data
  );
[0m17:58:37.672935 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "telegram_data.telegram_messages" does not exist
LINE 28:     from "Data_house"."telegram_data"."telegram_messages"
                  ^

[0m17:58:37.674933 [debug] [Thread-1 (]: On model.data_house.transform_messages: ROLLBACK
[0m17:58:37.676906 [debug] [Thread-1 (]: On model.data_house.transform_messages: Close
[0m17:58:37.819058 [debug] [Thread-1 (]: Database Error in model transform_messages (models\example\transform_messages.sql)
  relation "telegram_data.telegram_messages" does not exist
  LINE 28:     from "Data_house"."telegram_data"."telegram_messages"
                    ^
  compiled code at target\run\data_house\models\example\transform_messages.sql
[0m17:58:37.820061 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b4ea7647-1305-4379-b43c-23d4b0fa2d8a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000281B7B17C20>]}
[0m17:58:37.821065 [error] [Thread-1 (]: 2 of 3 ERROR creating sql view model analytics.transform_messages .............. [[31mERROR[0m in 0.49s]
[0m17:58:37.823063 [debug] [Thread-1 (]: Finished running node model.data_house.transform_messages
[0m17:58:37.823063 [debug] [Thread-1 (]: Began running node model.data_house.my_second_dbt_model
[0m17:58:37.824059 [debug] [Thread-4 (]: Marking all children of 'model.data_house.transform_messages' to be skipped because of status 'error'.  Reason: Database Error in model transform_messages (models\example\transform_messages.sql)
  relation "telegram_data.telegram_messages" does not exist
  LINE 28:     from "Data_house"."telegram_data"."telegram_messages"
                    ^
  compiled code at target\run\data_house\models\example\transform_messages.sql.
[0m17:58:37.825093 [info ] [Thread-1 (]: 3 of 3 START sql view model analytics.my_second_dbt_model ...................... [RUN]
[0m17:58:37.829071 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_house.transform_messages, now model.data_house.my_second_dbt_model)
[0m17:58:37.830064 [debug] [Thread-1 (]: Began compiling node model.data_house.my_second_dbt_model
[0m17:58:37.835064 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_house.my_second_dbt_model"
[0m17:58:37.840063 [debug] [Thread-1 (]: Began executing node model.data_house.my_second_dbt_model
[0m17:58:37.847083 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_house.my_second_dbt_model"
[0m17:58:37.850066 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m17:58:37.851061 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: BEGIN
[0m17:58:37.851061 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:58:37.939064 [debug] [Thread-1 (]: SQL status: BEGIN in 0.088 seconds
[0m17:58:37.940061 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m17:58:37.941063 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_second_dbt_model"} */

  create view "Data_house"."analytics"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "Data_house"."analytics"."my_first_dbt_model"
where id = 1
  );
[0m17:58:37.989741 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.047 seconds
[0m17:58:37.997741 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m17:58:37.998743 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_second_dbt_model"} */
alter table "Data_house"."analytics"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m17:58:37.999743 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:58:38.002738 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: COMMIT
[0m17:58:38.003742 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m17:58:38.003742 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: COMMIT
[0m17:58:38.045746 [debug] [Thread-1 (]: SQL status: COMMIT in 0.040 seconds
[0m17:58:38.054743 [debug] [Thread-1 (]: Applying DROP to: "Data_house"."analytics"."my_second_dbt_model__dbt_backup"
[0m17:58:38.066745 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m17:58:38.067746 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_second_dbt_model"} */
drop view if exists "Data_house"."analytics"."my_second_dbt_model__dbt_backup" cascade
[0m17:58:38.102741 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.032 seconds
[0m17:58:38.107742 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: Close
[0m17:58:38.109743 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b4ea7647-1305-4379-b43c-23d4b0fa2d8a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000281B731CCB0>]}
[0m17:58:38.112741 [info ] [Thread-1 (]: 3 of 3 OK created sql view model analytics.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.28s]
[0m17:58:38.116744 [debug] [Thread-1 (]: Finished running node model.data_house.my_second_dbt_model
[0m17:58:38.120742 [debug] [MainThread]: Using postgres connection "master"
[0m17:58:38.121745 [debug] [MainThread]: On master: BEGIN
[0m17:58:38.122744 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:58:38.228738 [debug] [MainThread]: SQL status: BEGIN in 0.106 seconds
[0m17:58:38.229738 [debug] [MainThread]: On master: COMMIT
[0m17:58:38.229738 [debug] [MainThread]: Using postgres connection "master"
[0m17:58:38.230734 [debug] [MainThread]: On master: COMMIT
[0m17:58:38.230734 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m17:58:38.231737 [debug] [MainThread]: On master: Close
[0m17:58:38.232736 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:58:38.233742 [debug] [MainThread]: Connection 'list_Data_house' was properly closed.
[0m17:58:38.233742 [debug] [MainThread]: Connection 'list_Data_house_analytics' was properly closed.
[0m17:58:38.234741 [debug] [MainThread]: Connection 'model.data_house.my_second_dbt_model' was properly closed.
[0m17:58:38.235737 [info ] [MainThread]: 
[0m17:58:38.237748 [info ] [MainThread]: Finished running 1 table model, 2 view models in 0 hours 0 minutes and 6.64 seconds (6.64s).
[0m17:58:38.239739 [debug] [MainThread]: Command end result
[0m17:58:38.341733 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\manifest.json
[0m17:58:38.346737 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\semantic_manifest.json
[0m17:58:38.357739 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\run_results.json
[0m17:58:38.358741 [info ] [MainThread]: 
[0m17:58:38.359655 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m17:58:38.360699 [info ] [MainThread]: 
[0m17:58:38.362674 [error] [MainThread]:   Database Error in model transform_messages (models\example\transform_messages.sql)
  relation "telegram_data.telegram_messages" does not exist
  LINE 28:     from "Data_house"."telegram_data"."telegram_messages"
                    ^
  compiled code at target\run\data_house\models\example\transform_messages.sql
[0m17:58:38.364672 [info ] [MainThread]: 
[0m17:58:38.366682 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
[0m17:58:38.368699 [debug] [MainThread]: Command `dbt run` failed at 17:58:38.368699 after 12.93 seconds
[0m17:58:38.369693 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000281B5BB2570>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000281B2F3C800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000281B58E5CA0>]}
[0m17:58:38.372699 [debug] [MainThread]: Flushing usage events
[0m17:58:40.266787 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:59:58.271856 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000237ABE0D3D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000237AB995C70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000237ABE0D970>]}


============================== 17:59:58.278852 | 645f0865-fe90-4e06-96cc-470dd304bee9 ==============================
[0m17:59:58.278852 [info ] [MainThread]: Running with dbt=1.9.2
[0m17:59:58.280856 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\Dagi\\Documents\\KAIM\\week-7\\Ethiopian-Medical-DataWarehouse\\data_house\\logs', 'profiles_dir': 'C:\\Users\\Dagi\\.dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m17:59:58.775852 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '645f0865-fe90-4e06-96cc-470dd304bee9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000237AB75DCA0>]}
[0m17:59:58.926852 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '645f0865-fe90-4e06-96cc-470dd304bee9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000237AC348C80>]}
[0m17:59:58.928855 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m17:59:59.408870 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m18:00:00.825333 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m18:00:00.827335 [debug] [MainThread]: Partial parsing: updated file: data_house://models\sources\sources.yml
[0m18:00:00.827335 [debug] [MainThread]: Partial parsing: updated file: data_house://models\example\transform_messages.sql
[0m18:00:01.790875 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '645f0865-fe90-4e06-96cc-470dd304bee9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000237AD9C4350>]}
[0m18:00:01.933886 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\manifest.json
[0m18:00:01.939887 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\semantic_manifest.json
[0m18:00:01.991880 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '645f0865-fe90-4e06-96cc-470dd304bee9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000237ADAD6C60>]}
[0m18:00:01.993886 [info ] [MainThread]: Found 3 models, 4 data tests, 1 source, 431 macros
[0m18:00:01.995888 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '645f0865-fe90-4e06-96cc-470dd304bee9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000237AC74EA50>]}
[0m18:00:02.022907 [info ] [MainThread]: 
[0m18:00:02.026879 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:00:02.043884 [info ] [MainThread]: 
[0m18:00:02.044881 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m18:00:02.055907 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Data_house'
[0m18:00:02.222881 [debug] [ThreadPool]: Using postgres connection "list_Data_house"
[0m18:00:02.224881 [debug] [ThreadPool]: On list_Data_house: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "connection_name": "list_Data_house"} */

    select distinct nspname from pg_namespace
  
[0m18:00:02.224881 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:00:02.299880 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.075 seconds
[0m18:00:02.303884 [debug] [ThreadPool]: On list_Data_house: Close
[0m18:00:02.306880 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Data_house_analytics'
[0m18:00:02.319873 [debug] [ThreadPool]: Using postgres connection "list_Data_house_analytics"
[0m18:00:02.320879 [debug] [ThreadPool]: On list_Data_house_analytics: BEGIN
[0m18:00:02.320879 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:00:02.380879 [debug] [ThreadPool]: SQL status: BEGIN in 0.060 seconds
[0m18:00:02.381879 [debug] [ThreadPool]: Using postgres connection "list_Data_house_analytics"
[0m18:00:02.382884 [debug] [ThreadPool]: On list_Data_house_analytics: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "connection_name": "list_Data_house_analytics"} */
select
      'Data_house' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'Data_house' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'Data_house' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m18:00:02.393880 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.011 seconds
[0m18:00:02.396874 [debug] [ThreadPool]: On list_Data_house_analytics: ROLLBACK
[0m18:00:02.396874 [debug] [ThreadPool]: On list_Data_house_analytics: Close
[0m18:00:02.412875 [debug] [MainThread]: Using postgres connection "master"
[0m18:00:02.412875 [debug] [MainThread]: On master: BEGIN
[0m18:00:02.413876 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:00:02.476878 [debug] [MainThread]: SQL status: BEGIN in 0.063 seconds
[0m18:00:02.477880 [debug] [MainThread]: Using postgres connection "master"
[0m18:00:02.477880 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m18:00:02.495874 [debug] [MainThread]: SQL status: SELECT 1 in 0.017 seconds
[0m18:00:02.497875 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '645f0865-fe90-4e06-96cc-470dd304bee9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000237ADA725A0>]}
[0m18:00:02.498875 [debug] [MainThread]: On master: ROLLBACK
[0m18:00:02.499885 [debug] [MainThread]: Using postgres connection "master"
[0m18:00:02.500880 [debug] [MainThread]: On master: BEGIN
[0m18:00:02.502879 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m18:00:02.502879 [debug] [MainThread]: On master: COMMIT
[0m18:00:02.503878 [debug] [MainThread]: Using postgres connection "master"
[0m18:00:02.503878 [debug] [MainThread]: On master: COMMIT
[0m18:00:02.504875 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:00:02.505878 [debug] [MainThread]: On master: Close
[0m18:00:02.509878 [debug] [Thread-1 (]: Began running node model.data_house.my_first_dbt_model
[0m18:00:02.510878 [info ] [Thread-1 (]: 1 of 3 START sql table model analytics.my_first_dbt_model ...................... [RUN]
[0m18:00:02.513880 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.data_house.my_first_dbt_model'
[0m18:00:02.514878 [debug] [Thread-1 (]: Began compiling node model.data_house.my_first_dbt_model
[0m18:00:02.539875 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_house.my_first_dbt_model"
[0m18:00:02.541877 [debug] [Thread-1 (]: Began executing node model.data_house.my_first_dbt_model
[0m18:00:02.613874 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_house.my_first_dbt_model"
[0m18:00:02.617881 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m18:00:02.618880 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: BEGIN
[0m18:00:02.618880 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m18:00:02.693883 [debug] [Thread-1 (]: SQL status: BEGIN in 0.075 seconds
[0m18:00:02.694882 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m18:00:02.695877 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_first_dbt_model"} */

  
    

  create  table "Data_house"."analytics"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m18:00:02.706877 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.009 seconds
[0m18:00:02.717877 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m18:00:02.718874 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_first_dbt_model"} */
alter table "Data_house"."analytics"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m18:00:02.719876 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:00:02.727875 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m18:00:02.729877 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_first_dbt_model"} */
alter table "Data_house"."analytics"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m18:00:02.731881 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:00:02.784879 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: COMMIT
[0m18:00:02.785878 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m18:00:02.785878 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: COMMIT
[0m18:00:02.787881 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m18:00:02.801881 [debug] [Thread-1 (]: Applying DROP to: "Data_house"."analytics"."my_first_dbt_model__dbt_backup"
[0m18:00:02.811878 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m18:00:02.812874 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_first_dbt_model"} */
drop table if exists "Data_house"."analytics"."my_first_dbt_model__dbt_backup" cascade
[0m18:00:02.818879 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.006 seconds
[0m18:00:02.824875 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: Close
[0m18:00:02.830881 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '645f0865-fe90-4e06-96cc-470dd304bee9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000237A968E7E0>]}
[0m18:00:02.834883 [info ] [Thread-1 (]: 1 of 3 OK created sql table model analytics.my_first_dbt_model ................. [[32mSELECT 2[0m in 0.31s]
[0m18:00:02.840887 [debug] [Thread-1 (]: Finished running node model.data_house.my_first_dbt_model
[0m18:00:02.841879 [debug] [Thread-1 (]: Began running node model.data_house.transform_messages
[0m18:00:02.843880 [info ] [Thread-1 (]: 2 of 3 START sql view model analytics.transform_messages ....................... [RUN]
[0m18:00:02.846883 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_house.my_first_dbt_model, now model.data_house.transform_messages)
[0m18:00:02.851880 [debug] [Thread-1 (]: Began compiling node model.data_house.transform_messages
[0m18:00:02.865880 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_house.transform_messages"
[0m18:00:02.870931 [debug] [Thread-1 (]: Began executing node model.data_house.transform_messages
[0m18:00:02.946879 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_house.transform_messages"
[0m18:00:02.949882 [debug] [Thread-1 (]: Using postgres connection "model.data_house.transform_messages"
[0m18:00:02.950886 [debug] [Thread-1 (]: On model.data_house.transform_messages: BEGIN
[0m18:00:02.951881 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:00:03.036885 [debug] [Thread-1 (]: SQL status: BEGIN in 0.085 seconds
[0m18:00:03.037881 [debug] [Thread-1 (]: Using postgres connection "model.data_house.transform_messages"
[0m18:00:03.038880 [debug] [Thread-1 (]: On model.data_house.transform_messages: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.transform_messages"} */

  create view "Data_house"."analytics"."transform_messages__dbt_tmp"
    
    
  as (
    -- models/example/transform_messages.sql

with cleaned_data as (
    select
        id,
        channel_title,
        channel_username,
        message_id,
        message,
        message_date,
        media_path,
        emoji_used,
        youtube_links,
        case 
            when emoji_used = 'No emoji' then false
            else true
        end as has_emoji,
        case 
            when youtube_links = 'No YouTube link' then false
            else true
        end as has_youtube_links
    from "Data_house"."telegram_data"."message"
)

select
    *,
    current_timestamp as transformed_at
from cleaned_data
  );
[0m18:00:03.041883 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "telegram_data.message" does not exist
LINE 28:     from "Data_house"."telegram_data"."message"
                  ^

[0m18:00:03.042883 [debug] [Thread-1 (]: On model.data_house.transform_messages: ROLLBACK
[0m18:00:03.043883 [debug] [Thread-1 (]: On model.data_house.transform_messages: Close
[0m18:00:03.056876 [debug] [Thread-1 (]: Database Error in model transform_messages (models\example\transform_messages.sql)
  relation "telegram_data.message" does not exist
  LINE 28:     from "Data_house"."telegram_data"."message"
                    ^
  compiled code at target\run\data_house\models\example\transform_messages.sql
[0m18:00:03.057876 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '645f0865-fe90-4e06-96cc-470dd304bee9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000237AE2B3D10>]}
[0m18:00:03.059878 [error] [Thread-1 (]: 2 of 3 ERROR creating sql view model analytics.transform_messages .............. [[31mERROR[0m in 0.21s]
[0m18:00:03.061881 [debug] [Thread-1 (]: Finished running node model.data_house.transform_messages
[0m18:00:03.062876 [debug] [Thread-1 (]: Began running node model.data_house.my_second_dbt_model
[0m18:00:03.063877 [debug] [Thread-4 (]: Marking all children of 'model.data_house.transform_messages' to be skipped because of status 'error'.  Reason: Database Error in model transform_messages (models\example\transform_messages.sql)
  relation "telegram_data.message" does not exist
  LINE 28:     from "Data_house"."telegram_data"."message"
                    ^
  compiled code at target\run\data_house\models\example\transform_messages.sql.
[0m18:00:03.064876 [info ] [Thread-1 (]: 3 of 3 START sql view model analytics.my_second_dbt_model ...................... [RUN]
[0m18:00:03.069882 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_house.transform_messages, now model.data_house.my_second_dbt_model)
[0m18:00:03.070882 [debug] [Thread-1 (]: Began compiling node model.data_house.my_second_dbt_model
[0m18:00:03.074876 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_house.my_second_dbt_model"
[0m18:00:03.077883 [debug] [Thread-1 (]: Began executing node model.data_house.my_second_dbt_model
[0m18:00:03.101948 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_house.my_second_dbt_model"
[0m18:00:03.103884 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m18:00:03.105882 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: BEGIN
[0m18:00:03.106884 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:00:03.247884 [debug] [Thread-1 (]: SQL status: BEGIN in 0.141 seconds
[0m18:00:03.249888 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m18:00:03.251934 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_second_dbt_model"} */

  create view "Data_house"."analytics"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "Data_house"."analytics"."my_first_dbt_model"
where id = 1
  );
[0m18:00:03.264878 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.011 seconds
[0m18:00:03.275881 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m18:00:03.276882 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_second_dbt_model"} */
alter table "Data_house"."analytics"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m18:00:03.277884 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:00:03.280879 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: COMMIT
[0m18:00:03.281883 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m18:00:03.282881 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: COMMIT
[0m18:00:03.285879 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m18:00:03.293882 [debug] [Thread-1 (]: Applying DROP to: "Data_house"."analytics"."my_second_dbt_model__dbt_backup"
[0m18:00:03.300883 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m18:00:03.302883 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_second_dbt_model"} */
drop view if exists "Data_house"."analytics"."my_second_dbt_model__dbt_backup" cascade
[0m18:00:03.304881 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.000 seconds
[0m18:00:03.307880 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: Close
[0m18:00:03.309877 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '645f0865-fe90-4e06-96cc-470dd304bee9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000237AE2DB2F0>]}
[0m18:00:03.312879 [info ] [Thread-1 (]: 3 of 3 OK created sql view model analytics.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.24s]
[0m18:00:03.315879 [debug] [Thread-1 (]: Finished running node model.data_house.my_second_dbt_model
[0m18:00:03.318878 [debug] [MainThread]: Using postgres connection "master"
[0m18:00:03.318878 [debug] [MainThread]: On master: BEGIN
[0m18:00:03.319879 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:00:03.415881 [debug] [MainThread]: SQL status: BEGIN in 0.096 seconds
[0m18:00:03.417880 [debug] [MainThread]: On master: COMMIT
[0m18:00:03.417880 [debug] [MainThread]: Using postgres connection "master"
[0m18:00:03.418880 [debug] [MainThread]: On master: COMMIT
[0m18:00:03.419878 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:00:03.420879 [debug] [MainThread]: On master: Close
[0m18:00:03.421882 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:00:03.422878 [debug] [MainThread]: Connection 'list_Data_house' was properly closed.
[0m18:00:03.423884 [debug] [MainThread]: Connection 'list_Data_house_analytics' was properly closed.
[0m18:00:03.424883 [debug] [MainThread]: Connection 'model.data_house.my_second_dbt_model' was properly closed.
[0m18:00:03.425881 [info ] [MainThread]: 
[0m18:00:03.427880 [info ] [MainThread]: Finished running 1 table model, 2 view models in 0 hours 0 minutes and 1.38 seconds (1.38s).
[0m18:00:03.431879 [debug] [MainThread]: Command end result
[0m18:00:03.521881 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\manifest.json
[0m18:00:03.527884 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\semantic_manifest.json
[0m18:00:03.543883 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\run_results.json
[0m18:00:03.545412 [info ] [MainThread]: 
[0m18:00:03.546813 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m18:00:03.547980 [info ] [MainThread]: 
[0m18:00:03.549611 [error] [MainThread]:   Database Error in model transform_messages (models\example\transform_messages.sql)
  relation "telegram_data.message" does not exist
  LINE 28:     from "Data_house"."telegram_data"."message"
                    ^
  compiled code at target\run\data_house\models\example\transform_messages.sql
[0m18:00:03.552724 [info ] [MainThread]: 
[0m18:00:03.555318 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
[0m18:00:03.562370 [debug] [MainThread]: Command `dbt run` failed at 18:00:03.561822 after 5.71 seconds
[0m18:00:03.563456 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000237A94B4C50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000237AB7D8830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000237AB7D9610>]}
[0m18:00:03.564546 [debug] [MainThread]: Flushing usage events
[0m18:00:04.549162 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:00:27.931502 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BA2753A3F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BA2763EAE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BA24BE8BC0>]}


============================== 18:00:27.941493 | bb9892e1-7329-4922-ab99-3a2af7d66444 ==============================
[0m18:00:27.941493 [info ] [MainThread]: Running with dbt=1.9.2
[0m18:00:27.943495 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Dagi\\.dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\Dagi\\Documents\\KAIM\\week-7\\Ethiopian-Medical-DataWarehouse\\data_house\\logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m18:00:28.390490 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bb9892e1-7329-4922-ab99-3a2af7d66444', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BA24DBF7A0>]}
[0m18:00:28.527493 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'bb9892e1-7329-4922-ab99-3a2af7d66444', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BA27B6E9C0>]}
[0m18:00:28.529492 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m18:00:29.063913 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m18:00:29.399914 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:00:29.399914 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:00:29.501913 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bb9892e1-7329-4922-ab99-3a2af7d66444', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BA27A53560>]}
[0m18:00:29.662910 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\manifest.json
[0m18:00:29.669910 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\semantic_manifest.json
[0m18:00:29.729912 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bb9892e1-7329-4922-ab99-3a2af7d66444', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BA28FF7E00>]}
[0m18:00:29.730911 [info ] [MainThread]: Found 3 models, 4 data tests, 1 source, 431 macros
[0m18:00:29.732913 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bb9892e1-7329-4922-ab99-3a2af7d66444', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BA27BBA750>]}
[0m18:00:29.739923 [info ] [MainThread]: 
[0m18:00:29.747929 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:00:29.750918 [info ] [MainThread]: 
[0m18:00:29.757917 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m18:00:29.773914 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Data_house'
[0m18:00:29.944916 [debug] [ThreadPool]: Using postgres connection "list_Data_house"
[0m18:00:29.945913 [debug] [ThreadPool]: On list_Data_house: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "connection_name": "list_Data_house"} */

    select distinct nspname from pg_namespace
  
[0m18:00:29.946916 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:00:30.040915 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.094 seconds
[0m18:00:30.043911 [debug] [ThreadPool]: On list_Data_house: Close
[0m18:00:30.047933 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Data_house_analytics'
[0m18:00:30.066913 [debug] [ThreadPool]: Using postgres connection "list_Data_house_analytics"
[0m18:00:30.067911 [debug] [ThreadPool]: On list_Data_house_analytics: BEGIN
[0m18:00:30.068913 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:00:30.137911 [debug] [ThreadPool]: SQL status: BEGIN in 0.069 seconds
[0m18:00:30.138915 [debug] [ThreadPool]: Using postgres connection "list_Data_house_analytics"
[0m18:00:30.139913 [debug] [ThreadPool]: On list_Data_house_analytics: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "connection_name": "list_Data_house_analytics"} */
select
      'Data_house' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'Data_house' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'Data_house' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m18:00:30.149911 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.010 seconds
[0m18:00:30.151913 [debug] [ThreadPool]: On list_Data_house_analytics: ROLLBACK
[0m18:00:30.152913 [debug] [ThreadPool]: On list_Data_house_analytics: Close
[0m18:00:30.166909 [debug] [MainThread]: Using postgres connection "master"
[0m18:00:30.167911 [debug] [MainThread]: On master: BEGIN
[0m18:00:30.167911 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:00:30.243913 [debug] [MainThread]: SQL status: BEGIN in 0.075 seconds
[0m18:00:30.244912 [debug] [MainThread]: Using postgres connection "master"
[0m18:00:30.245911 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m18:00:30.264912 [debug] [MainThread]: SQL status: SELECT 1 in 0.018 seconds
[0m18:00:30.267910 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bb9892e1-7329-4922-ab99-3a2af7d66444', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BA28FF7F80>]}
[0m18:00:30.268912 [debug] [MainThread]: On master: ROLLBACK
[0m18:00:30.270913 [debug] [MainThread]: Using postgres connection "master"
[0m18:00:30.271909 [debug] [MainThread]: On master: BEGIN
[0m18:00:30.272909 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m18:00:30.273911 [debug] [MainThread]: On master: COMMIT
[0m18:00:30.274912 [debug] [MainThread]: Using postgres connection "master"
[0m18:00:30.275911 [debug] [MainThread]: On master: COMMIT
[0m18:00:30.276918 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:00:30.277911 [debug] [MainThread]: On master: Close
[0m18:00:30.282916 [debug] [Thread-1 (]: Began running node model.data_house.my_first_dbt_model
[0m18:00:30.284913 [info ] [Thread-1 (]: 1 of 3 START sql table model analytics.my_first_dbt_model ...................... [RUN]
[0m18:00:30.287911 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.data_house.my_first_dbt_model'
[0m18:00:30.288911 [debug] [Thread-1 (]: Began compiling node model.data_house.my_first_dbt_model
[0m18:00:30.319913 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_house.my_first_dbt_model"
[0m18:00:30.321913 [debug] [Thread-1 (]: Began executing node model.data_house.my_first_dbt_model
[0m18:00:30.402911 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_house.my_first_dbt_model"
[0m18:00:30.404914 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m18:00:30.406916 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: BEGIN
[0m18:00:30.406916 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m18:00:30.611623 [debug] [Thread-1 (]: SQL status: BEGIN in 0.204 seconds
[0m18:00:30.612629 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m18:00:30.613610 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_first_dbt_model"} */

  
    

  create  table "Data_house"."analytics"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m18:00:30.621611 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.007 seconds
[0m18:00:30.631614 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m18:00:30.632611 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_first_dbt_model"} */
alter table "Data_house"."analytics"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m18:00:30.633611 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:00:30.637605 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m18:00:30.640608 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_first_dbt_model"} */
alter table "Data_house"."analytics"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m18:00:30.641614 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:00:30.674604 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: COMMIT
[0m18:00:30.675606 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m18:00:30.676606 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: COMMIT
[0m18:00:30.678610 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m18:00:30.688609 [debug] [Thread-1 (]: Applying DROP to: "Data_house"."analytics"."my_first_dbt_model__dbt_backup"
[0m18:00:30.696608 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m18:00:30.697609 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_first_dbt_model"} */
drop table if exists "Data_house"."analytics"."my_first_dbt_model__dbt_backup" cascade
[0m18:00:30.738607 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.041 seconds
[0m18:00:30.743604 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: Close
[0m18:00:30.748612 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb9892e1-7329-4922-ab99-3a2af7d66444', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BA24DBE8A0>]}
[0m18:00:30.750610 [info ] [Thread-1 (]: 1 of 3 OK created sql table model analytics.my_first_dbt_model ................. [[32mSELECT 2[0m in 0.46s]
[0m18:00:30.751611 [debug] [Thread-1 (]: Finished running node model.data_house.my_first_dbt_model
[0m18:00:30.752611 [debug] [Thread-1 (]: Began running node model.data_house.transform_messages
[0m18:00:30.753610 [info ] [Thread-1 (]: 2 of 3 START sql view model analytics.transform_messages ....................... [RUN]
[0m18:00:30.755609 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_house.my_first_dbt_model, now model.data_house.transform_messages)
[0m18:00:30.756610 [debug] [Thread-1 (]: Began compiling node model.data_house.transform_messages
[0m18:00:30.760606 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_house.transform_messages"
[0m18:00:30.762608 [debug] [Thread-1 (]: Began executing node model.data_house.transform_messages
[0m18:00:30.799621 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_house.transform_messages"
[0m18:00:30.802615 [debug] [Thread-1 (]: Using postgres connection "model.data_house.transform_messages"
[0m18:00:30.804619 [debug] [Thread-1 (]: On model.data_house.transform_messages: BEGIN
[0m18:00:30.805614 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:00:30.897397 [debug] [Thread-1 (]: SQL status: BEGIN in 0.092 seconds
[0m18:00:30.898903 [debug] [Thread-1 (]: Using postgres connection "model.data_house.transform_messages"
[0m18:00:30.900328 [debug] [Thread-1 (]: On model.data_house.transform_messages: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.transform_messages"} */

  create view "Data_house"."analytics"."transform_messages__dbt_tmp"
    
    
  as (
    -- models/example/transform_messages.sql

with cleaned_data as (
    select
        id,
        channel_title,
        channel_username,
        message_id,
        message,
        message_date,
        media_path,
        emoji_used,
        youtube_links,
        case 
            when emoji_used = 'No emoji' then false
            else true
        end as has_emoji,
        case 
            when youtube_links = 'No YouTube link' then false
            else true
        end as has_youtube_links
    from "Data_house"."telegram_data"."message"
)

select
    *,
    current_timestamp as transformed_at
from cleaned_data
  );
[0m18:00:30.902560 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "telegram_data.message" does not exist
LINE 28:     from "Data_house"."telegram_data"."message"
                  ^

[0m18:00:30.904154 [debug] [Thread-1 (]: On model.data_house.transform_messages: ROLLBACK
[0m18:00:30.906540 [debug] [Thread-1 (]: On model.data_house.transform_messages: Close
[0m18:00:30.920513 [debug] [Thread-1 (]: Database Error in model transform_messages (models\example\transform_messages.sql)
  relation "telegram_data.message" does not exist
  LINE 28:     from "Data_house"."telegram_data"."message"
                    ^
  compiled code at target\run\data_house\models\example\transform_messages.sql
[0m18:00:30.921528 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb9892e1-7329-4922-ab99-3a2af7d66444', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BA27C3B290>]}
[0m18:00:30.922527 [error] [Thread-1 (]: 2 of 3 ERROR creating sql view model analytics.transform_messages .............. [[31mERROR[0m in 0.17s]
[0m18:00:30.923530 [debug] [Thread-1 (]: Finished running node model.data_house.transform_messages
[0m18:00:30.924529 [debug] [Thread-1 (]: Began running node model.data_house.my_second_dbt_model
[0m18:00:30.925525 [debug] [Thread-4 (]: Marking all children of 'model.data_house.transform_messages' to be skipped because of status 'error'.  Reason: Database Error in model transform_messages (models\example\transform_messages.sql)
  relation "telegram_data.message" does not exist
  LINE 28:     from "Data_house"."telegram_data"."message"
                    ^
  compiled code at target\run\data_house\models\example\transform_messages.sql.
[0m18:00:30.926525 [info ] [Thread-1 (]: 3 of 3 START sql view model analytics.my_second_dbt_model ...................... [RUN]
[0m18:00:30.929534 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_house.transform_messages, now model.data_house.my_second_dbt_model)
[0m18:00:30.929534 [debug] [Thread-1 (]: Began compiling node model.data_house.my_second_dbt_model
[0m18:00:30.939538 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_house.my_second_dbt_model"
[0m18:00:30.942535 [debug] [Thread-1 (]: Began executing node model.data_house.my_second_dbt_model
[0m18:00:30.953527 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_house.my_second_dbt_model"
[0m18:00:30.955531 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m18:00:30.957532 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: BEGIN
[0m18:00:30.958530 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:00:31.038404 [debug] [Thread-1 (]: SQL status: BEGIN in 0.080 seconds
[0m18:00:31.040401 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m18:00:31.042403 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_second_dbt_model"} */

  create view "Data_house"."analytics"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "Data_house"."analytics"."my_first_dbt_model"
where id = 1
  );
[0m18:00:31.052410 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.008 seconds
[0m18:00:31.057399 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m18:00:31.058399 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_second_dbt_model"} */
alter table "Data_house"."analytics"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m18:00:31.059403 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:00:31.061399 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: COMMIT
[0m18:00:31.062399 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m18:00:31.063399 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: COMMIT
[0m18:00:31.068403 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m18:00:31.072404 [debug] [Thread-1 (]: Applying DROP to: "Data_house"."analytics"."my_second_dbt_model__dbt_backup"
[0m18:00:31.076401 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m18:00:31.077404 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_second_dbt_model"} */
drop view if exists "Data_house"."analytics"."my_second_dbt_model__dbt_backup" cascade
[0m18:00:31.078403 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.000 seconds
[0m18:00:31.080404 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: Close
[0m18:00:31.082410 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb9892e1-7329-4922-ab99-3a2af7d66444', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BA2933CCB0>]}
[0m18:00:31.083407 [info ] [Thread-1 (]: 3 of 3 OK created sql view model analytics.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.15s]
[0m18:00:31.086406 [debug] [Thread-1 (]: Finished running node model.data_house.my_second_dbt_model
[0m18:00:31.088404 [debug] [MainThread]: Using postgres connection "master"
[0m18:00:31.089406 [debug] [MainThread]: On master: BEGIN
[0m18:00:31.089406 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:00:31.169407 [debug] [MainThread]: SQL status: BEGIN in 0.079 seconds
[0m18:00:31.170407 [debug] [MainThread]: On master: COMMIT
[0m18:00:31.170407 [debug] [MainThread]: Using postgres connection "master"
[0m18:00:31.171407 [debug] [MainThread]: On master: COMMIT
[0m18:00:31.171407 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:00:31.172406 [debug] [MainThread]: On master: Close
[0m18:00:31.173409 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:00:31.173409 [debug] [MainThread]: Connection 'list_Data_house' was properly closed.
[0m18:00:31.174408 [debug] [MainThread]: Connection 'list_Data_house_analytics' was properly closed.
[0m18:00:31.175412 [debug] [MainThread]: Connection 'model.data_house.my_second_dbt_model' was properly closed.
[0m18:00:31.176404 [info ] [MainThread]: 
[0m18:00:31.177407 [info ] [MainThread]: Finished running 1 table model, 2 view models in 0 hours 0 minutes and 1.42 seconds (1.42s).
[0m18:00:31.314470 [debug] [MainThread]: Command end result
[0m18:00:31.391431 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\manifest.json
[0m18:00:31.395429 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\semantic_manifest.json
[0m18:00:31.405439 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\run_results.json
[0m18:00:31.406454 [info ] [MainThread]: 
[0m18:00:31.407444 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m18:00:31.409437 [info ] [MainThread]: 
[0m18:00:31.410429 [error] [MainThread]:   Database Error in model transform_messages (models\example\transform_messages.sql)
  relation "telegram_data.message" does not exist
  LINE 28:     from "Data_house"."telegram_data"."message"
                    ^
  compiled code at target\run\data_house\models\example\transform_messages.sql
[0m18:00:31.412434 [info ] [MainThread]: 
[0m18:00:31.414429 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
[0m18:00:31.418426 [debug] [MainThread]: Command `dbt run` failed at 18:00:31.417455 after 3.74 seconds
[0m18:00:31.419455 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BA278F1CA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BA275948F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BA27597560>]}
[0m18:00:31.420426 [debug] [MainThread]: Flushing usage events
[0m18:00:32.366717 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:05:08.805760 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298EB239A60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298EB96E9F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298EB2399D0>]}


============================== 18:05:08.875121 | 0f6976ae-3873-4da5-a57b-7e00da35f536 ==============================
[0m18:05:08.875121 [info ] [MainThread]: Running with dbt=1.9.2
[0m18:05:08.893486 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': 'C:\\Users\\Dagi\\.dbt', 'log_path': 'C:\\Users\\Dagi\\Documents\\KAIM\\week-7\\Ethiopian-Medical-DataWarehouse\\data_house\\logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m18:05:09.464962 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0f6976ae-3873-4da5-a57b-7e00da35f536', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298EBEDB0B0>]}
[0m18:05:09.559935 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0f6976ae-3873-4da5-a57b-7e00da35f536', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298EBEFCB90>]}
[0m18:05:09.561940 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m18:05:10.082584 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m18:05:10.506319 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m18:05:10.507321 [debug] [MainThread]: Partial parsing: updated file: data_house://models\sources\sources.yml
[0m18:05:10.507321 [debug] [MainThread]: Partial parsing: updated file: data_house://models\example\transform_messages.sql
[0m18:05:11.141968 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0f6976ae-3873-4da5-a57b-7e00da35f536', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298ED447830>]}
[0m18:05:11.265960 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\manifest.json
[0m18:05:11.290964 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\semantic_manifest.json
[0m18:05:12.465222 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0f6976ae-3873-4da5-a57b-7e00da35f536', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298ED54EA50>]}
[0m18:05:12.469227 [info ] [MainThread]: Found 3 models, 4 data tests, 1 source, 431 macros
[0m18:05:12.474225 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0f6976ae-3873-4da5-a57b-7e00da35f536', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298EBF35910>]}
[0m18:05:12.485217 [info ] [MainThread]: 
[0m18:05:12.488212 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:05:12.490211 [info ] [MainThread]: 
[0m18:05:12.493218 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m18:05:12.516207 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Data_house'
[0m18:05:13.595820 [debug] [ThreadPool]: Using postgres connection "list_Data_house"
[0m18:05:13.612301 [debug] [ThreadPool]: On list_Data_house: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "connection_name": "list_Data_house"} */

    select distinct nspname from pg_namespace
  
[0m18:05:13.613341 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:05:14.648494 [debug] [ThreadPool]: SQL status: SELECT 5 in 1.035 seconds
[0m18:05:14.652498 [debug] [ThreadPool]: On list_Data_house: Close
[0m18:05:14.712492 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Data_house_analytics'
[0m18:05:14.733493 [debug] [ThreadPool]: Using postgres connection "list_Data_house_analytics"
[0m18:05:14.735502 [debug] [ThreadPool]: On list_Data_house_analytics: BEGIN
[0m18:05:14.736498 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:05:14.838490 [debug] [ThreadPool]: SQL status: BEGIN in 0.102 seconds
[0m18:05:14.838490 [debug] [ThreadPool]: Using postgres connection "list_Data_house_analytics"
[0m18:05:14.839488 [debug] [ThreadPool]: On list_Data_house_analytics: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "connection_name": "list_Data_house_analytics"} */
select
      'Data_house' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'Data_house' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'Data_house' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m18:05:15.395376 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.555 seconds
[0m18:05:15.397374 [debug] [ThreadPool]: On list_Data_house_analytics: ROLLBACK
[0m18:05:15.399371 [debug] [ThreadPool]: On list_Data_house_analytics: Close
[0m18:05:15.414377 [debug] [MainThread]: Using postgres connection "master"
[0m18:05:15.415373 [debug] [MainThread]: On master: BEGIN
[0m18:05:15.416396 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:05:15.489381 [debug] [MainThread]: SQL status: BEGIN in 0.072 seconds
[0m18:05:15.490371 [debug] [MainThread]: Using postgres connection "master"
[0m18:05:15.491377 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m18:05:15.577149 [debug] [MainThread]: SQL status: SELECT 1 in 0.084 seconds
[0m18:05:15.579175 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0f6976ae-3873-4da5-a57b-7e00da35f536', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298ED3B2630>]}
[0m18:05:15.580175 [debug] [MainThread]: On master: ROLLBACK
[0m18:05:15.581177 [debug] [MainThread]: Using postgres connection "master"
[0m18:05:15.581177 [debug] [MainThread]: On master: BEGIN
[0m18:05:15.582175 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m18:05:15.583174 [debug] [MainThread]: On master: COMMIT
[0m18:05:15.584176 [debug] [MainThread]: Using postgres connection "master"
[0m18:05:15.584176 [debug] [MainThread]: On master: COMMIT
[0m18:05:15.585156 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:05:15.586155 [debug] [MainThread]: On master: Close
[0m18:05:15.631151 [debug] [Thread-1 (]: Began running node model.data_house.my_first_dbt_model
[0m18:05:15.632155 [info ] [Thread-1 (]: 1 of 3 START sql table model analytics.my_first_dbt_model ...................... [RUN]
[0m18:05:15.634174 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.data_house.my_first_dbt_model'
[0m18:05:15.635158 [debug] [Thread-1 (]: Began compiling node model.data_house.my_first_dbt_model
[0m18:05:15.649156 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_house.my_first_dbt_model"
[0m18:05:15.652156 [debug] [Thread-1 (]: Began executing node model.data_house.my_first_dbt_model
[0m18:05:15.717148 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_house.my_first_dbt_model"
[0m18:05:15.720158 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m18:05:15.721175 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: BEGIN
[0m18:05:15.721175 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m18:05:15.784577 [debug] [Thread-1 (]: SQL status: BEGIN in 0.063 seconds
[0m18:05:15.785584 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m18:05:15.786576 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_first_dbt_model"} */

  
    

  create  table "Data_house"."analytics"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m18:05:15.855553 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.069 seconds
[0m18:05:15.867531 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m18:05:15.867531 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_first_dbt_model"} */
alter table "Data_house"."analytics"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m18:05:15.870078 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m18:05:15.875128 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m18:05:15.876129 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_first_dbt_model"} */
alter table "Data_house"."analytics"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m18:05:15.878106 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:05:15.909111 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: COMMIT
[0m18:05:15.910109 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m18:05:15.910109 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: COMMIT
[0m18:05:15.929530 [debug] [Thread-1 (]: SQL status: COMMIT in 0.019 seconds
[0m18:05:15.939549 [debug] [Thread-1 (]: Applying DROP to: "Data_house"."analytics"."my_first_dbt_model__dbt_backup"
[0m18:05:15.947550 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m18:05:15.948551 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_first_dbt_model"} */
drop table if exists "Data_house"."analytics"."my_first_dbt_model__dbt_backup" cascade
[0m18:05:16.126813 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.178 seconds
[0m18:05:16.137811 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: Close
[0m18:05:16.146804 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f6976ae-3873-4da5-a57b-7e00da35f536', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298E90EEAB0>]}
[0m18:05:16.148812 [info ] [Thread-1 (]: 1 of 3 OK created sql table model analytics.my_first_dbt_model ................. [[32mSELECT 2[0m in 0.51s]
[0m18:05:16.152807 [debug] [Thread-1 (]: Finished running node model.data_house.my_first_dbt_model
[0m18:05:16.153803 [debug] [Thread-1 (]: Began running node model.data_house.transform_messages
[0m18:05:16.155804 [info ] [Thread-1 (]: 2 of 3 START sql view model analytics.transform_messages ....................... [RUN]
[0m18:05:16.157813 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_house.my_first_dbt_model, now model.data_house.transform_messages)
[0m18:05:16.159808 [debug] [Thread-1 (]: Began compiling node model.data_house.transform_messages
[0m18:05:16.166803 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_house.transform_messages"
[0m18:05:16.175807 [debug] [Thread-1 (]: Began executing node model.data_house.transform_messages
[0m18:05:16.214823 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_house.transform_messages"
[0m18:05:16.216800 [debug] [Thread-1 (]: Using postgres connection "model.data_house.transform_messages"
[0m18:05:16.217824 [debug] [Thread-1 (]: On model.data_house.transform_messages: BEGIN
[0m18:05:16.218805 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:05:16.282800 [debug] [Thread-1 (]: SQL status: BEGIN in 0.064 seconds
[0m18:05:16.283821 [debug] [Thread-1 (]: Using postgres connection "model.data_house.transform_messages"
[0m18:05:16.284798 [debug] [Thread-1 (]: On model.data_house.transform_messages: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.transform_messages"} */

  create view "Data_house"."analytics"."transform_messages__dbt_tmp"
    
    
  as (
    -- models/example/transform_messages.sql

with cleaned_data as (
    select
        id,
        channel_title,
        channel_username,
        message_id,
        message,
        message_date,
        media_path,
        emoji_used,
        youtube_links,
        case 
            when emoji_used = 'No emoji' then false
            else true
        end as has_emoji,
        case 
            when youtube_links = 'No YouTube link' then false
            else true
        end as has_youtube_links
    from "Data_house"."telegram_data"."telegram_messages"
)

select
    *,
    current_timestamp as transformed_at
from cleaned_data
  );
[0m18:05:16.347960 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "telegram_data.telegram_messages" does not exist
LINE 28:     from "Data_house"."telegram_data"."telegram_messages"
                  ^

[0m18:05:16.349929 [debug] [Thread-1 (]: On model.data_house.transform_messages: ROLLBACK
[0m18:05:16.353926 [debug] [Thread-1 (]: On model.data_house.transform_messages: Close
[0m18:05:16.506471 [debug] [Thread-1 (]: Database Error in model transform_messages (models\example\transform_messages.sql)
  relation "telegram_data.telegram_messages" does not exist
  LINE 28:     from "Data_house"."telegram_data"."telegram_messages"
                    ^
  compiled code at target\run\data_house\models\example\transform_messages.sql
[0m18:05:16.508475 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f6976ae-3873-4da5-a57b-7e00da35f536', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298ED3B21E0>]}
[0m18:05:16.509474 [error] [Thread-1 (]: 2 of 3 ERROR creating sql view model analytics.transform_messages .............. [[31mERROR[0m in 0.35s]
[0m18:05:16.512502 [debug] [Thread-1 (]: Finished running node model.data_house.transform_messages
[0m18:05:16.513499 [debug] [Thread-1 (]: Began running node model.data_house.my_second_dbt_model
[0m18:05:16.514484 [debug] [Thread-4 (]: Marking all children of 'model.data_house.transform_messages' to be skipped because of status 'error'.  Reason: Database Error in model transform_messages (models\example\transform_messages.sql)
  relation "telegram_data.telegram_messages" does not exist
  LINE 28:     from "Data_house"."telegram_data"."telegram_messages"
                    ^
  compiled code at target\run\data_house\models\example\transform_messages.sql.
[0m18:05:16.515482 [info ] [Thread-1 (]: 3 of 3 START sql view model analytics.my_second_dbt_model ...................... [RUN]
[0m18:05:16.520486 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_house.transform_messages, now model.data_house.my_second_dbt_model)
[0m18:05:16.521489 [debug] [Thread-1 (]: Began compiling node model.data_house.my_second_dbt_model
[0m18:05:16.528484 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_house.my_second_dbt_model"
[0m18:05:16.533480 [debug] [Thread-1 (]: Began executing node model.data_house.my_second_dbt_model
[0m18:05:16.546476 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_house.my_second_dbt_model"
[0m18:05:16.548475 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m18:05:16.549479 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: BEGIN
[0m18:05:16.549479 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:05:16.620480 [debug] [Thread-1 (]: SQL status: BEGIN in 0.071 seconds
[0m18:05:16.621503 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m18:05:16.622500 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_second_dbt_model"} */

  create view "Data_house"."analytics"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "Data_house"."analytics"."my_first_dbt_model"
where id = 1
  );
[0m18:05:16.685478 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.063 seconds
[0m18:05:16.692472 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m18:05:16.693479 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_second_dbt_model"} */
alter table "Data_house"."analytics"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m18:05:16.695476 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:05:16.698478 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: COMMIT
[0m18:05:16.700476 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m18:05:16.701481 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: COMMIT
[0m18:05:16.704472 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m18:05:16.710479 [debug] [Thread-1 (]: Applying DROP to: "Data_house"."analytics"."my_second_dbt_model__dbt_backup"
[0m18:05:16.718482 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m18:05:16.720475 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_second_dbt_model"} */
drop view if exists "Data_house"."analytics"."my_second_dbt_model__dbt_backup" cascade
[0m18:05:16.722474 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.001 seconds
[0m18:05:16.726471 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: Close
[0m18:05:16.727478 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f6976ae-3873-4da5-a57b-7e00da35f536', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298EDD3A030>]}
[0m18:05:16.728473 [info ] [Thread-1 (]: 3 of 3 OK created sql view model analytics.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.21s]
[0m18:05:16.732474 [debug] [Thread-1 (]: Finished running node model.data_house.my_second_dbt_model
[0m18:05:16.735475 [debug] [MainThread]: Using postgres connection "master"
[0m18:05:16.736487 [debug] [MainThread]: On master: BEGIN
[0m18:05:16.737483 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:05:16.814861 [debug] [MainThread]: SQL status: BEGIN in 0.077 seconds
[0m18:05:16.815861 [debug] [MainThread]: On master: COMMIT
[0m18:05:16.815861 [debug] [MainThread]: Using postgres connection "master"
[0m18:05:16.816853 [debug] [MainThread]: On master: COMMIT
[0m18:05:16.816853 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:05:16.817856 [debug] [MainThread]: On master: Close
[0m18:05:16.818864 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:05:16.820932 [debug] [MainThread]: Connection 'list_Data_house' was properly closed.
[0m18:05:16.821869 [debug] [MainThread]: Connection 'list_Data_house_analytics' was properly closed.
[0m18:05:16.821869 [debug] [MainThread]: Connection 'model.data_house.my_second_dbt_model' was properly closed.
[0m18:05:16.837869 [info ] [MainThread]: 
[0m18:05:16.839864 [info ] [MainThread]: Finished running 1 table model, 2 view models in 0 hours 0 minutes and 4.33 seconds (4.33s).
[0m18:05:16.841859 [debug] [MainThread]: Command end result
[0m18:05:16.892710 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\manifest.json
[0m18:05:16.895707 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\semantic_manifest.json
[0m18:05:16.908741 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\run_results.json
[0m18:05:16.909711 [info ] [MainThread]: 
[0m18:05:16.911735 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m18:05:16.912709 [info ] [MainThread]: 
[0m18:05:16.913711 [error] [MainThread]:   Database Error in model transform_messages (models\example\transform_messages.sql)
  relation "telegram_data.telegram_messages" does not exist
  LINE 28:     from "Data_house"."telegram_data"."telegram_messages"
                    ^
  compiled code at target\run\data_house\models\example\transform_messages.sql
[0m18:05:16.915713 [info ] [MainThread]: 
[0m18:05:16.917711 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
[0m18:05:16.923490 [debug] [MainThread]: Command `dbt run` failed at 18:05:16.922486 after 8.93 seconds
[0m18:05:16.926525 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298EB1FA2D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298EB1F9820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298EC000A10>]}
[0m18:05:16.927486 [debug] [MainThread]: Flushing usage events
[0m18:05:18.631451 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:10:38.580865 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017FE84F48C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017FE608ADE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017FE84F4050>]}


============================== 18:10:38.668280 | da0e7df6-b9f6-40c4-b37b-b7aa9ee3b072 ==============================
[0m18:10:38.668280 [info ] [MainThread]: Running with dbt=1.9.2
[0m18:10:38.686355 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Dagi\\.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\Dagi\\Documents\\KAIM\\week-7\\Ethiopian-Medical-DataWarehouse\\data_house\\logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m18:10:39.876745 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'da0e7df6-b9f6-40c4-b37b-b7aa9ee3b072', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017FE865C080>]}
[0m18:10:39.983751 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'da0e7df6-b9f6-40c4-b37b-b7aa9ee3b072', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017FE87C15B0>]}
[0m18:10:39.986730 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m18:10:40.593700 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m18:10:41.158254 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:10:41.159255 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:10:41.242232 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'da0e7df6-b9f6-40c4-b37b-b7aa9ee3b072', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017FE8B76ED0>]}
[0m18:10:41.418232 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\manifest.json
[0m18:10:41.439234 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\semantic_manifest.json
[0m18:10:42.500564 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'da0e7df6-b9f6-40c4-b37b-b7aa9ee3b072', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017FE9F56CF0>]}
[0m18:10:42.501588 [info ] [MainThread]: Found 3 models, 4 data tests, 1 source, 431 macros
[0m18:10:42.503851 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'da0e7df6-b9f6-40c4-b37b-b7aa9ee3b072', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017FE8C081A0>]}
[0m18:10:42.506847 [info ] [MainThread]: 
[0m18:10:42.507804 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:10:42.509829 [info ] [MainThread]: 
[0m18:10:42.511824 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m18:10:42.526906 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Data_house'
[0m18:10:43.347409 [debug] [ThreadPool]: Using postgres connection "list_Data_house"
[0m18:10:43.349410 [debug] [ThreadPool]: On list_Data_house: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "connection_name": "list_Data_house"} */

    select distinct nspname from pg_namespace
  
[0m18:10:43.351383 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:10:43.576835 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.225 seconds
[0m18:10:43.581830 [debug] [ThreadPool]: On list_Data_house: Close
[0m18:10:43.613272 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Data_house_analytics'
[0m18:10:43.640233 [debug] [ThreadPool]: Using postgres connection "list_Data_house_analytics"
[0m18:10:43.641283 [debug] [ThreadPool]: On list_Data_house_analytics: BEGIN
[0m18:10:43.643280 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:10:43.720762 [debug] [ThreadPool]: SQL status: BEGIN in 0.077 seconds
[0m18:10:43.721776 [debug] [ThreadPool]: Using postgres connection "list_Data_house_analytics"
[0m18:10:43.721776 [debug] [ThreadPool]: On list_Data_house_analytics: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "connection_name": "list_Data_house_analytics"} */
select
      'Data_house' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'Data_house' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'Data_house' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m18:10:43.867754 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.145 seconds
[0m18:10:43.872759 [debug] [ThreadPool]: On list_Data_house_analytics: ROLLBACK
[0m18:10:43.873752 [debug] [ThreadPool]: On list_Data_house_analytics: Close
[0m18:10:43.889757 [debug] [MainThread]: Using postgres connection "master"
[0m18:10:43.891759 [debug] [MainThread]: On master: BEGIN
[0m18:10:43.892759 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:10:43.990749 [debug] [MainThread]: SQL status: BEGIN in 0.098 seconds
[0m18:10:43.991750 [debug] [MainThread]: Using postgres connection "master"
[0m18:10:43.992748 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m18:10:44.212271 [debug] [MainThread]: SQL status: SELECT 1 in 0.219 seconds
[0m18:10:44.222042 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'da0e7df6-b9f6-40c4-b37b-b7aa9ee3b072', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017FE8AF30B0>]}
[0m18:10:44.224037 [debug] [MainThread]: On master: ROLLBACK
[0m18:10:44.226036 [debug] [MainThread]: Using postgres connection "master"
[0m18:10:44.228037 [debug] [MainThread]: On master: BEGIN
[0m18:10:44.230079 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m18:10:44.232037 [debug] [MainThread]: On master: COMMIT
[0m18:10:44.234038 [debug] [MainThread]: Using postgres connection "master"
[0m18:10:44.236077 [debug] [MainThread]: On master: COMMIT
[0m18:10:44.239052 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m18:10:44.241077 [debug] [MainThread]: On master: Close
[0m18:10:44.318665 [debug] [Thread-1 (]: Began running node model.data_house.my_first_dbt_model
[0m18:10:44.322668 [info ] [Thread-1 (]: 1 of 3 START sql table model analytics.my_first_dbt_model ...................... [RUN]
[0m18:10:44.326628 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.data_house.my_first_dbt_model'
[0m18:10:44.328629 [debug] [Thread-1 (]: Began compiling node model.data_house.my_first_dbt_model
[0m18:10:44.366641 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_house.my_first_dbt_model"
[0m18:10:44.369622 [debug] [Thread-1 (]: Began executing node model.data_house.my_first_dbt_model
[0m18:10:44.438642 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_house.my_first_dbt_model"
[0m18:10:44.440624 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m18:10:44.440624 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: BEGIN
[0m18:10:44.441642 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m18:10:44.708526 [debug] [Thread-1 (]: SQL status: BEGIN in 0.266 seconds
[0m18:10:44.708526 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m18:10:44.709526 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_first_dbt_model"} */

  
    

  create  table "Data_house"."analytics"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m18:10:44.903468 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.193 seconds
[0m18:10:44.922464 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m18:10:44.923465 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_first_dbt_model"} */
alter table "Data_house"."analytics"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m18:10:45.017924 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.093 seconds
[0m18:10:45.022677 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m18:10:45.025677 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_first_dbt_model"} */
alter table "Data_house"."analytics"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m18:10:45.027673 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:10:45.066673 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: COMMIT
[0m18:10:45.067679 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m18:10:45.068675 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: COMMIT
[0m18:10:45.077002 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m18:10:45.094987 [debug] [Thread-1 (]: Applying DROP to: "Data_house"."analytics"."my_first_dbt_model__dbt_backup"
[0m18:10:45.110990 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m18:10:45.111988 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_first_dbt_model"} */
drop table if exists "Data_house"."analytics"."my_first_dbt_model__dbt_backup" cascade
[0m18:10:45.203114 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.089 seconds
[0m18:10:45.213911 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: Close
[0m18:10:45.225899 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da0e7df6-b9f6-40c4-b37b-b7aa9ee3b072', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017FE7E28380>]}
[0m18:10:45.228909 [info ] [Thread-1 (]: 1 of 3 OK created sql table model analytics.my_first_dbt_model ................. [[32mSELECT 2[0m in 0.89s]
[0m18:10:45.233932 [debug] [Thread-1 (]: Finished running node model.data_house.my_first_dbt_model
[0m18:10:45.234932 [debug] [Thread-1 (]: Began running node model.data_house.transform_messages
[0m18:10:45.237894 [info ] [Thread-1 (]: 2 of 3 START sql view model analytics.transform_messages ....................... [RUN]
[0m18:10:45.242912 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_house.my_first_dbt_model, now model.data_house.transform_messages)
[0m18:10:45.244899 [debug] [Thread-1 (]: Began compiling node model.data_house.transform_messages
[0m18:10:45.253894 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_house.transform_messages"
[0m18:10:45.258889 [debug] [Thread-1 (]: Began executing node model.data_house.transform_messages
[0m18:10:45.304889 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_house.transform_messages"
[0m18:10:45.306888 [debug] [Thread-1 (]: Using postgres connection "model.data_house.transform_messages"
[0m18:10:45.307889 [debug] [Thread-1 (]: On model.data_house.transform_messages: BEGIN
[0m18:10:45.308887 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:10:45.381891 [debug] [Thread-1 (]: SQL status: BEGIN in 0.074 seconds
[0m18:10:45.382890 [debug] [Thread-1 (]: Using postgres connection "model.data_house.transform_messages"
[0m18:10:45.383888 [debug] [Thread-1 (]: On model.data_house.transform_messages: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.transform_messages"} */

  create view "Data_house"."analytics"."transform_messages__dbt_tmp"
    
    
  as (
    -- models/example/transform_messages.sql

with cleaned_data as (
    select
        id,
        channel_title,
        channel_username,
        message_id,
        message,
        message_date,
        media_path,
        emoji_used,
        youtube_links,
        case 
            when emoji_used = 'No emoji' then false
            else true
        end as has_emoji,
        case 
            when youtube_links = 'No YouTube link' then false
            else true
        end as has_youtube_links
    from "Data_house"."telegram_data"."telegram_messages"
)

select
    *,
    current_timestamp as transformed_at
from cleaned_data
  );
[0m18:10:45.471914 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "telegram_data.telegram_messages" does not exist
LINE 28:     from "Data_house"."telegram_data"."telegram_messages"
                  ^

[0m18:10:45.475909 [debug] [Thread-1 (]: On model.data_house.transform_messages: ROLLBACK
[0m18:10:45.480907 [debug] [Thread-1 (]: On model.data_house.transform_messages: Close
[0m18:10:45.749003 [debug] [Thread-1 (]: Database Error in model transform_messages (models\example\transform_messages.sql)
  relation "telegram_data.telegram_messages" does not exist
  LINE 28:     from "Data_house"."telegram_data"."telegram_messages"
                    ^
  compiled code at target\run\data_house\models\example\transform_messages.sql
[0m18:10:45.751009 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da0e7df6-b9f6-40c4-b37b-b7aa9ee3b072', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017FEA6F9070>]}
[0m18:10:45.754019 [error] [Thread-1 (]: 2 of 3 ERROR creating sql view model analytics.transform_messages .............. [[31mERROR[0m in 0.51s]
[0m18:10:45.759008 [debug] [Thread-1 (]: Finished running node model.data_house.transform_messages
[0m18:10:45.764001 [debug] [Thread-1 (]: Began running node model.data_house.my_second_dbt_model
[0m18:10:45.769996 [debug] [Thread-4 (]: Marking all children of 'model.data_house.transform_messages' to be skipped because of status 'error'.  Reason: Database Error in model transform_messages (models\example\transform_messages.sql)
  relation "telegram_data.telegram_messages" does not exist
  LINE 28:     from "Data_house"."telegram_data"."telegram_messages"
                    ^
  compiled code at target\run\data_house\models\example\transform_messages.sql.
[0m18:10:45.772994 [info ] [Thread-1 (]: 3 of 3 START sql view model analytics.my_second_dbt_model ...................... [RUN]
[0m18:10:45.784009 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_house.transform_messages, now model.data_house.my_second_dbt_model)
[0m18:10:45.784992 [debug] [Thread-1 (]: Began compiling node model.data_house.my_second_dbt_model
[0m18:10:45.795995 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_house.my_second_dbt_model"
[0m18:10:45.801045 [debug] [Thread-1 (]: Began executing node model.data_house.my_second_dbt_model
[0m18:10:45.813987 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_house.my_second_dbt_model"
[0m18:10:45.817988 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m18:10:45.819985 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: BEGIN
[0m18:10:45.821987 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:10:45.885981 [debug] [Thread-1 (]: SQL status: BEGIN in 0.064 seconds
[0m18:10:45.886990 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m18:10:45.887983 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_second_dbt_model"} */

  create view "Data_house"."analytics"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "Data_house"."analytics"."my_first_dbt_model"
where id = 1
  );
[0m18:10:45.955258 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.066 seconds
[0m18:10:45.960251 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m18:10:45.961252 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_second_dbt_model"} */
alter table "Data_house"."analytics"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m18:10:45.962700 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:10:45.964750 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: COMMIT
[0m18:10:45.965750 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m18:10:45.965750 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: COMMIT
[0m18:10:45.968482 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m18:10:45.972497 [debug] [Thread-1 (]: Applying DROP to: "Data_house"."analytics"."my_second_dbt_model__dbt_backup"
[0m18:10:45.977499 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m18:10:45.977499 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_second_dbt_model"} */
drop view if exists "Data_house"."analytics"."my_second_dbt_model__dbt_backup" cascade
[0m18:10:45.994526 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.016 seconds
[0m18:10:45.996568 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: Close
[0m18:10:45.997569 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da0e7df6-b9f6-40c4-b37b-b7aa9ee3b072', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017FEA71DD30>]}
[0m18:10:45.999549 [info ] [Thread-1 (]: 3 of 3 OK created sql view model analytics.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.21s]
[0m18:10:46.002547 [debug] [Thread-1 (]: Finished running node model.data_house.my_second_dbt_model
[0m18:10:46.005545 [debug] [MainThread]: Using postgres connection "master"
[0m18:10:46.006560 [debug] [MainThread]: On master: BEGIN
[0m18:10:46.006560 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:10:46.082565 [debug] [MainThread]: SQL status: BEGIN in 0.075 seconds
[0m18:10:46.082565 [debug] [MainThread]: On master: COMMIT
[0m18:10:46.083566 [debug] [MainThread]: Using postgres connection "master"
[0m18:10:46.083566 [debug] [MainThread]: On master: COMMIT
[0m18:10:46.084565 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:10:46.085566 [debug] [MainThread]: On master: Close
[0m18:10:46.086548 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:10:46.087549 [debug] [MainThread]: Connection 'list_Data_house' was properly closed.
[0m18:10:46.088547 [debug] [MainThread]: Connection 'list_Data_house_analytics' was properly closed.
[0m18:10:46.089543 [debug] [MainThread]: Connection 'model.data_house.my_second_dbt_model' was properly closed.
[0m18:10:46.098590 [info ] [MainThread]: 
[0m18:10:46.099543 [info ] [MainThread]: Finished running 1 table model, 2 view models in 0 hours 0 minutes and 3.58 seconds (3.58s).
[0m18:10:46.101547 [debug] [MainThread]: Command end result
[0m18:10:46.151547 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\manifest.json
[0m18:10:46.158544 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\semantic_manifest.json
[0m18:10:46.168542 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\run_results.json
[0m18:10:46.169551 [info ] [MainThread]: 
[0m18:10:46.171546 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m18:10:46.172566 [info ] [MainThread]: 
[0m18:10:46.174543 [error] [MainThread]:   Database Error in model transform_messages (models\example\transform_messages.sql)
  relation "telegram_data.telegram_messages" does not exist
  LINE 28:     from "Data_house"."telegram_data"."telegram_messages"
                    ^
  compiled code at target\run\data_house\models\example\transform_messages.sql
[0m18:10:46.176545 [info ] [MainThread]: 
[0m18:10:46.177546 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
[0m18:10:46.180552 [debug] [MainThread]: Command `dbt run` failed at 18:10:46.179548 after 8.78 seconds
[0m18:10:46.182591 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017FE86D75F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017FE85D1E20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017FE86998B0>]}
[0m18:10:46.183549 [debug] [MainThread]: Flushing usage events
[0m18:10:47.749509 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:15:56.068318 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023C88737EF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023C8B6F9880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023C89CAEDB0>]}


============================== 18:15:56.181103 | cafb55d8-7d3a-4bd6-a467-60acf903c049 ==============================
[0m18:15:56.181103 [info ] [MainThread]: Running with dbt=1.9.2
[0m18:15:56.220586 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Dagi\\.dbt', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\Dagi\\Documents\\KAIM\\week-7\\Ethiopian-Medical-DataWarehouse\\data_house\\logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m18:15:57.715408 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cafb55d8-7d3a-4bd6-a467-60acf903c049', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023C8BEFD100>]}
[0m18:15:57.836405 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'cafb55d8-7d3a-4bd6-a467-60acf903c049', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023C8C20D190>]}
[0m18:15:57.839410 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m18:15:58.525483 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m18:15:58.751836 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m18:15:58.754368 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'cafb55d8-7d3a-4bd6-a467-60acf903c049', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023C8D538800>]}
[0m18:16:01.583888 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cafb55d8-7d3a-4bd6-a467-60acf903c049', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023C8D6694C0>]}
[0m18:16:01.796865 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\manifest.json
[0m18:16:01.825723 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\semantic_manifest.json
[0m18:16:03.074783 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cafb55d8-7d3a-4bd6-a467-60acf903c049', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023C8D757260>]}
[0m18:16:03.075783 [info ] [MainThread]: Found 3 models, 4 data tests, 1 source, 431 macros
[0m18:16:03.077782 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cafb55d8-7d3a-4bd6-a467-60acf903c049', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023C89122C90>]}
[0m18:16:03.082788 [info ] [MainThread]: 
[0m18:16:03.084788 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:16:03.086791 [info ] [MainThread]: 
[0m18:16:03.091792 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m18:16:03.126793 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Data_house'
[0m18:16:04.597341 [debug] [ThreadPool]: Using postgres connection "list_Data_house"
[0m18:16:04.599378 [debug] [ThreadPool]: On list_Data_house: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "connection_name": "list_Data_house"} */

    select distinct nspname from pg_namespace
  
[0m18:16:04.601379 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:16:05.302296 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.701 seconds
[0m18:16:05.308290 [debug] [ThreadPool]: On list_Data_house: Close
[0m18:16:05.351298 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Data_house_public'
[0m18:16:05.367301 [debug] [ThreadPool]: Using postgres connection "list_Data_house_public"
[0m18:16:05.368302 [debug] [ThreadPool]: On list_Data_house_public: BEGIN
[0m18:16:05.369301 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:16:05.481912 [debug] [ThreadPool]: SQL status: BEGIN in 0.113 seconds
[0m18:16:05.482941 [debug] [ThreadPool]: Using postgres connection "list_Data_house_public"
[0m18:16:05.482941 [debug] [ThreadPool]: On list_Data_house_public: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "connection_name": "list_Data_house_public"} */
select
      'Data_house' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'Data_house' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
    union all
    select
      'Data_house' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public'
  
[0m18:16:05.584206 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.100 seconds
[0m18:16:05.586966 [debug] [ThreadPool]: On list_Data_house_public: ROLLBACK
[0m18:16:05.588080 [debug] [ThreadPool]: On list_Data_house_public: Close
[0m18:16:05.597359 [debug] [MainThread]: Using postgres connection "master"
[0m18:16:05.598359 [debug] [MainThread]: On master: BEGIN
[0m18:16:05.598359 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:16:05.659937 [debug] [MainThread]: SQL status: BEGIN in 0.061 seconds
[0m18:16:05.660937 [debug] [MainThread]: Using postgres connection "master"
[0m18:16:05.661937 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m18:16:05.817162 [debug] [MainThread]: SQL status: SELECT 1 in 0.154 seconds
[0m18:16:05.822164 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cafb55d8-7d3a-4bd6-a467-60acf903c049', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023C8DAF0470>]}
[0m18:16:05.824200 [debug] [MainThread]: On master: ROLLBACK
[0m18:16:05.826170 [debug] [MainThread]: Using postgres connection "master"
[0m18:16:05.827160 [debug] [MainThread]: On master: BEGIN
[0m18:16:05.829180 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m18:16:05.831195 [debug] [MainThread]: On master: COMMIT
[0m18:16:05.833173 [debug] [MainThread]: Using postgres connection "master"
[0m18:16:05.834172 [debug] [MainThread]: On master: COMMIT
[0m18:16:05.836176 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:16:05.837174 [debug] [MainThread]: On master: Close
[0m18:16:05.846177 [debug] [Thread-1 (]: Began running node model.data_house.my_first_dbt_model
[0m18:16:05.848161 [info ] [Thread-1 (]: 1 of 3 START sql table model public.my_first_dbt_model ......................... [RUN]
[0m18:16:05.852177 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.data_house.my_first_dbt_model'
[0m18:16:05.853175 [debug] [Thread-1 (]: Began compiling node model.data_house.my_first_dbt_model
[0m18:16:05.879160 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_house.my_first_dbt_model"
[0m18:16:05.884156 [debug] [Thread-1 (]: Began executing node model.data_house.my_first_dbt_model
[0m18:16:05.951173 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_house.my_first_dbt_model"
[0m18:16:05.953153 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m18:16:05.955158 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: BEGIN
[0m18:16:05.955158 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m18:16:06.020152 [debug] [Thread-1 (]: SQL status: BEGIN in 0.065 seconds
[0m18:16:06.021172 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m18:16:06.022160 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_first_dbt_model"} */

  
    

  create  table "Data_house"."public"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m18:16:06.320859 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.298 seconds
[0m18:16:06.361855 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m18:16:06.363856 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_first_dbt_model"} */
alter table "Data_house"."public"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m18:16:06.457187 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.092 seconds
[0m18:16:06.484207 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: COMMIT
[0m18:16:06.485210 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m18:16:06.485210 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: COMMIT
[0m18:16:06.489117 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m18:16:06.500139 [debug] [Thread-1 (]: Applying DROP to: "Data_house"."public"."my_first_dbt_model__dbt_backup"
[0m18:16:06.508138 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m18:16:06.509140 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_first_dbt_model"} */
drop table if exists "Data_house"."public"."my_first_dbt_model__dbt_backup" cascade
[0m18:16:06.569935 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.059 seconds
[0m18:16:06.580959 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: Close
[0m18:16:06.613730 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cafb55d8-7d3a-4bd6-a467-60acf903c049', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023C892AE540>]}
[0m18:16:06.615761 [info ] [Thread-1 (]: 1 of 3 OK created sql table model public.my_first_dbt_model .................... [[32mSELECT 2[0m in 0.73s]
[0m18:16:06.618786 [debug] [Thread-1 (]: Finished running node model.data_house.my_first_dbt_model
[0m18:16:06.620811 [debug] [Thread-1 (]: Began running node model.data_house.transform_messages
[0m18:16:06.623764 [info ] [Thread-1 (]: 2 of 3 START sql view model public.transform_messages .......................... [RUN]
[0m18:16:06.638472 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_house.my_first_dbt_model, now model.data_house.transform_messages)
[0m18:16:06.645462 [debug] [Thread-1 (]: Began compiling node model.data_house.transform_messages
[0m18:16:06.670451 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_house.transform_messages"
[0m18:16:06.692446 [debug] [Thread-1 (]: Began executing node model.data_house.transform_messages
[0m18:16:06.766446 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_house.transform_messages"
[0m18:16:06.769447 [debug] [Thread-1 (]: Using postgres connection "model.data_house.transform_messages"
[0m18:16:06.770447 [debug] [Thread-1 (]: On model.data_house.transform_messages: BEGIN
[0m18:16:06.774447 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:16:06.901445 [debug] [Thread-1 (]: SQL status: BEGIN in 0.127 seconds
[0m18:16:06.901445 [debug] [Thread-1 (]: Using postgres connection "model.data_house.transform_messages"
[0m18:16:06.902445 [debug] [Thread-1 (]: On model.data_house.transform_messages: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.transform_messages"} */

  create view "Data_house"."public"."transform_messages__dbt_tmp"
    
    
  as (
    -- models/example/transform_messages.sql

with cleaned_data as (
    select
        id,
        channel_title,
        channel_username,
        message_id,
        message,
        message_date,
        media_path,
        emoji_used,
        youtube_links,
        case 
            when emoji_used = 'No emoji' then false
            else true
        end as has_emoji,
        case 
            when youtube_links = 'No YouTube link' then false
            else true
        end as has_youtube_links
    from "Data_house"."telegram_data"."telegram_messages"
)

select
    *,
    current_timestamp as transformed_at
from cleaned_data
  );
[0m18:16:07.146201 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "telegram_data.telegram_messages" does not exist
LINE 28:     from "Data_house"."telegram_data"."telegram_messages"
                  ^

[0m18:16:07.147201 [debug] [Thread-1 (]: On model.data_house.transform_messages: ROLLBACK
[0m18:16:07.148198 [debug] [Thread-1 (]: On model.data_house.transform_messages: Close
[0m18:16:07.350346 [debug] [Thread-1 (]: Database Error in model transform_messages (models\example\transform_messages.sql)
  relation "telegram_data.telegram_messages" does not exist
  LINE 28:     from "Data_house"."telegram_data"."telegram_messages"
                    ^
  compiled code at target\run\data_house\models\example\transform_messages.sql
[0m18:16:07.352351 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cafb55d8-7d3a-4bd6-a467-60acf903c049', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023C8DAFF680>]}
[0m18:16:07.353351 [error] [Thread-1 (]: 2 of 3 ERROR creating sql view model public.transform_messages ................. [[31mERROR[0m in 0.71s]
[0m18:16:07.356557 [debug] [Thread-1 (]: Finished running node model.data_house.transform_messages
[0m18:16:07.357552 [debug] [Thread-1 (]: Began running node model.data_house.my_second_dbt_model
[0m18:16:07.358551 [debug] [Thread-4 (]: Marking all children of 'model.data_house.transform_messages' to be skipped because of status 'error'.  Reason: Database Error in model transform_messages (models\example\transform_messages.sql)
  relation "telegram_data.telegram_messages" does not exist
  LINE 28:     from "Data_house"."telegram_data"."telegram_messages"
                    ^
  compiled code at target\run\data_house\models\example\transform_messages.sql.
[0m18:16:07.360115 [info ] [Thread-1 (]: 3 of 3 START sql view model public.my_second_dbt_model ......................... [RUN]
[0m18:16:07.365144 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_house.transform_messages, now model.data_house.my_second_dbt_model)
[0m18:16:07.366143 [debug] [Thread-1 (]: Began compiling node model.data_house.my_second_dbt_model
[0m18:16:07.376143 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_house.my_second_dbt_model"
[0m18:16:07.381147 [debug] [Thread-1 (]: Began executing node model.data_house.my_second_dbt_model
[0m18:16:07.395167 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_house.my_second_dbt_model"
[0m18:16:07.398146 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m18:16:07.400148 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: BEGIN
[0m18:16:07.402157 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:16:07.477139 [debug] [Thread-1 (]: SQL status: BEGIN in 0.075 seconds
[0m18:16:07.477139 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m18:16:07.478134 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_second_dbt_model"} */

  create view "Data_house"."public"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "Data_house"."public"."my_first_dbt_model"
where id = 1
  );
[0m18:16:07.580317 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.101 seconds
[0m18:16:07.595360 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m18:16:07.597362 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_second_dbt_model"} */
alter table "Data_house"."public"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m18:16:07.605330 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.006 seconds
[0m18:16:07.611346 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: COMMIT
[0m18:16:07.612346 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m18:16:07.613347 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: COMMIT
[0m18:16:07.625408 [debug] [Thread-1 (]: SQL status: COMMIT in 0.011 seconds
[0m18:16:07.635406 [debug] [Thread-1 (]: Applying DROP to: "Data_house"."public"."my_second_dbt_model__dbt_backup"
[0m18:16:07.686664 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m18:16:07.689639 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_second_dbt_model"} */
drop view if exists "Data_house"."public"."my_second_dbt_model__dbt_backup" cascade
[0m18:16:07.692665 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.001 seconds
[0m18:16:07.698664 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: Close
[0m18:16:07.700626 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cafb55d8-7d3a-4bd6-a467-60acf903c049', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023C8DAFD760>]}
[0m18:16:07.702641 [info ] [Thread-1 (]: 3 of 3 OK created sql view model public.my_second_dbt_model .................... [[32mCREATE VIEW[0m in 0.34s]
[0m18:16:07.707617 [debug] [Thread-1 (]: Finished running node model.data_house.my_second_dbt_model
[0m18:16:07.712615 [debug] [MainThread]: Using postgres connection "master"
[0m18:16:07.713613 [debug] [MainThread]: On master: BEGIN
[0m18:16:07.714613 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:16:07.818120 [debug] [MainThread]: SQL status: BEGIN in 0.103 seconds
[0m18:16:07.819231 [debug] [MainThread]: On master: COMMIT
[0m18:16:07.819787 [debug] [MainThread]: Using postgres connection "master"
[0m18:16:07.821012 [debug] [MainThread]: On master: COMMIT
[0m18:16:07.822127 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:16:07.823346 [debug] [MainThread]: On master: Close
[0m18:16:07.824679 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:16:07.825696 [debug] [MainThread]: Connection 'list_Data_house' was properly closed.
[0m18:16:07.826701 [debug] [MainThread]: Connection 'list_Data_house_public' was properly closed.
[0m18:16:07.827702 [debug] [MainThread]: Connection 'model.data_house.my_second_dbt_model' was properly closed.
[0m18:16:07.848171 [info ] [MainThread]: 
[0m18:16:07.849385 [info ] [MainThread]: Finished running 1 table model, 2 view models in 0 hours 0 minutes and 4.74 seconds (4.74s).
[0m18:16:07.853039 [debug] [MainThread]: Command end result
[0m18:16:07.929812 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\manifest.json
[0m18:16:07.933810 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\semantic_manifest.json
[0m18:16:07.948816 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\run_results.json
[0m18:16:07.949812 [info ] [MainThread]: 
[0m18:16:07.950810 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m18:16:07.952810 [info ] [MainThread]: 
[0m18:16:07.953812 [error] [MainThread]:   Database Error in model transform_messages (models\example\transform_messages.sql)
  relation "telegram_data.telegram_messages" does not exist
  LINE 28:     from "Data_house"."telegram_data"."telegram_messages"
                    ^
  compiled code at target\run\data_house\models\example\transform_messages.sql
[0m18:16:07.996736 [info ] [MainThread]: 
[0m18:16:07.997731 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
[0m18:16:08.000726 [debug] [MainThread]: Command `dbt run` failed at 18:16:08.000726 after 13.80 seconds
[0m18:16:08.001727 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023C8B75D7F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023C8BCB5D30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023C8D8FB6B0>]}
[0m18:16:08.001727 [debug] [MainThread]: Flushing usage events
[0m18:16:09.677807 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:18:40.790181 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000190773A66F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019077D56F30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001907956DC10>]}


============================== 18:18:40.798189 | 25e6f3f5-9b81-449e-b41f-818e375b30ae ==============================
[0m18:18:40.798189 [info ] [MainThread]: Running with dbt=1.9.2
[0m18:18:40.800204 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\Dagi\\Documents\\KAIM\\week-7\\Ethiopian-Medical-DataWarehouse\\data_house\\logs', 'debug': 'False', 'profiles_dir': 'C:\\Users\\Dagi\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m18:18:41.224180 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '25e6f3f5-9b81-449e-b41f-818e375b30ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001907A132B70>]}
[0m18:18:41.327180 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '25e6f3f5-9b81-449e-b41f-818e375b30ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001907A1584A0>]}
[0m18:18:41.329189 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m18:18:41.758391 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m18:18:42.123483 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m18:18:42.124484 [debug] [MainThread]: Partial parsing: updated file: data_house://models\sources\sources.yml
[0m18:18:42.873463 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '25e6f3f5-9b81-449e-b41f-818e375b30ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001907B690680>]}
[0m18:18:43.018465 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\manifest.json
[0m18:18:43.024463 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\semantic_manifest.json
[0m18:18:43.080462 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '25e6f3f5-9b81-449e-b41f-818e375b30ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001907B8E2BA0>]}
[0m18:18:43.082470 [info ] [MainThread]: Found 3 models, 4 data tests, 1 source, 431 macros
[0m18:18:43.083461 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '25e6f3f5-9b81-449e-b41f-818e375b30ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001907B710170>]}
[0m18:18:43.087462 [info ] [MainThread]: 
[0m18:18:43.089466 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:18:43.090464 [info ] [MainThread]: 
[0m18:18:43.093467 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m18:18:43.120465 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Data_house'
[0m18:18:43.302459 [debug] [ThreadPool]: Using postgres connection "list_Data_house"
[0m18:18:43.303462 [debug] [ThreadPool]: On list_Data_house: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "connection_name": "list_Data_house"} */

    select distinct nspname from pg_namespace
  
[0m18:18:43.304461 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:18:43.388464 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.084 seconds
[0m18:18:43.391460 [debug] [ThreadPool]: On list_Data_house: Close
[0m18:18:43.395466 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Data_house_public'
[0m18:18:43.407462 [debug] [ThreadPool]: Using postgres connection "list_Data_house_public"
[0m18:18:43.408464 [debug] [ThreadPool]: On list_Data_house_public: BEGIN
[0m18:18:43.409464 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:18:43.487464 [debug] [ThreadPool]: SQL status: BEGIN in 0.078 seconds
[0m18:18:43.488460 [debug] [ThreadPool]: Using postgres connection "list_Data_house_public"
[0m18:18:43.489465 [debug] [ThreadPool]: On list_Data_house_public: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "connection_name": "list_Data_house_public"} */
select
      'Data_house' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'Data_house' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
    union all
    select
      'Data_house' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public'
  
[0m18:18:43.501457 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.011 seconds
[0m18:18:43.503462 [debug] [ThreadPool]: On list_Data_house_public: ROLLBACK
[0m18:18:43.504462 [debug] [ThreadPool]: On list_Data_house_public: Close
[0m18:18:43.517458 [debug] [MainThread]: Using postgres connection "master"
[0m18:18:43.518464 [debug] [MainThread]: On master: BEGIN
[0m18:18:43.519465 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:18:43.595462 [debug] [MainThread]: SQL status: BEGIN in 0.077 seconds
[0m18:18:43.596463 [debug] [MainThread]: Using postgres connection "master"
[0m18:18:43.597460 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m18:18:43.612463 [debug] [MainThread]: SQL status: SELECT 2 in 0.013 seconds
[0m18:18:43.615466 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '25e6f3f5-9b81-449e-b41f-818e375b30ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001907A390AD0>]}
[0m18:18:43.616462 [debug] [MainThread]: On master: ROLLBACK
[0m18:18:43.618464 [debug] [MainThread]: Using postgres connection "master"
[0m18:18:43.618464 [debug] [MainThread]: On master: BEGIN
[0m18:18:43.619465 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m18:18:43.620463 [debug] [MainThread]: On master: COMMIT
[0m18:18:43.620463 [debug] [MainThread]: Using postgres connection "master"
[0m18:18:43.621461 [debug] [MainThread]: On master: COMMIT
[0m18:18:43.621461 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:18:43.622461 [debug] [MainThread]: On master: Close
[0m18:18:43.627464 [debug] [Thread-1 (]: Began running node model.data_house.my_first_dbt_model
[0m18:18:43.628467 [info ] [Thread-1 (]: 1 of 3 START sql table model public.my_first_dbt_model ......................... [RUN]
[0m18:18:43.631465 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.data_house.my_first_dbt_model'
[0m18:18:43.632469 [debug] [Thread-1 (]: Began compiling node model.data_house.my_first_dbt_model
[0m18:18:43.658458 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_house.my_first_dbt_model"
[0m18:18:43.660469 [debug] [Thread-1 (]: Began executing node model.data_house.my_first_dbt_model
[0m18:18:43.751464 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_house.my_first_dbt_model"
[0m18:18:43.759467 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m18:18:43.761469 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: BEGIN
[0m18:18:43.762463 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m18:18:43.847287 [debug] [Thread-1 (]: SQL status: BEGIN in 0.085 seconds
[0m18:18:43.849292 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m18:18:43.850690 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_first_dbt_model"} */

  
    

  create  table "Data_house"."public"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m18:18:43.861745 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.009 seconds
[0m18:18:43.877262 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m18:18:43.878263 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_first_dbt_model"} */
alter table "Data_house"."public"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m18:18:43.879265 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m18:18:43.887258 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m18:18:43.887258 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_first_dbt_model"} */
alter table "Data_house"."public"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m18:18:43.889266 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:18:43.938888 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: COMMIT
[0m18:18:43.939888 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m18:18:43.940886 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: COMMIT
[0m18:18:43.942888 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m18:18:43.954885 [debug] [Thread-1 (]: Applying DROP to: "Data_house"."public"."my_first_dbt_model__dbt_backup"
[0m18:18:43.962885 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_first_dbt_model"
[0m18:18:43.964889 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_first_dbt_model"} */
drop table if exists "Data_house"."public"."my_first_dbt_model__dbt_backup" cascade
[0m18:18:43.998464 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.032 seconds
[0m18:18:44.006456 [debug] [Thread-1 (]: On model.data_house.my_first_dbt_model: Close
[0m18:18:44.011462 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '25e6f3f5-9b81-449e-b41f-818e375b30ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001907749E570>]}
[0m18:18:44.013462 [info ] [Thread-1 (]: 1 of 3 OK created sql table model public.my_first_dbt_model .................... [[32mSELECT 2[0m in 0.38s]
[0m18:18:44.016460 [debug] [Thread-1 (]: Finished running node model.data_house.my_first_dbt_model
[0m18:18:44.017459 [debug] [Thread-1 (]: Began running node model.data_house.transform_messages
[0m18:18:44.018460 [info ] [Thread-1 (]: 2 of 3 START sql view model public.transform_messages .......................... [RUN]
[0m18:18:44.020464 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_house.my_first_dbt_model, now model.data_house.transform_messages)
[0m18:18:44.021465 [debug] [Thread-1 (]: Began compiling node model.data_house.transform_messages
[0m18:18:44.032468 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_house.transform_messages"
[0m18:18:44.056468 [debug] [Thread-1 (]: Began executing node model.data_house.transform_messages
[0m18:18:44.096461 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_house.transform_messages"
[0m18:18:44.099465 [debug] [Thread-1 (]: Using postgres connection "model.data_house.transform_messages"
[0m18:18:44.100464 [debug] [Thread-1 (]: On model.data_house.transform_messages: BEGIN
[0m18:18:44.101461 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:18:44.162463 [debug] [Thread-1 (]: SQL status: BEGIN in 0.061 seconds
[0m18:18:44.178459 [debug] [Thread-1 (]: Using postgres connection "model.data_house.transform_messages"
[0m18:18:44.178459 [debug] [Thread-1 (]: On model.data_house.transform_messages: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.transform_messages"} */

  create view "Data_house"."public"."transform_messages__dbt_tmp"
    
    
  as (
    -- models/example/transform_messages.sql

with cleaned_data as (
    select
        id,
        channel_title,
        channel_username,
        message_id,
        message,
        message_date,
        media_path,
        emoji_used,
        youtube_links,
        case 
            when emoji_used = 'No emoji' then false
            else true
        end as has_emoji,
        case 
            when youtube_links = 'No YouTube link' then false
            else true
        end as has_youtube_links
    from "Data_house"."public"."telegram_messages"
)

select
    *,
    current_timestamp as transformed_at
from cleaned_data
  );
[0m18:18:44.400466 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.221 seconds
[0m18:18:44.412463 [debug] [Thread-1 (]: Using postgres connection "model.data_house.transform_messages"
[0m18:18:44.413466 [debug] [Thread-1 (]: On model.data_house.transform_messages: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.transform_messages"} */
alter table "Data_house"."public"."transform_messages__dbt_tmp" rename to "transform_messages"
[0m18:18:44.417481 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:18:44.426466 [debug] [Thread-1 (]: On model.data_house.transform_messages: COMMIT
[0m18:18:44.427466 [debug] [Thread-1 (]: Using postgres connection "model.data_house.transform_messages"
[0m18:18:44.428467 [debug] [Thread-1 (]: On model.data_house.transform_messages: COMMIT
[0m18:18:44.434462 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m18:18:44.442465 [debug] [Thread-1 (]: Applying DROP to: "Data_house"."public"."transform_messages__dbt_backup"
[0m18:18:44.453465 [debug] [Thread-1 (]: Using postgres connection "model.data_house.transform_messages"
[0m18:18:44.454466 [debug] [Thread-1 (]: On model.data_house.transform_messages: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.transform_messages"} */
drop view if exists "Data_house"."public"."transform_messages__dbt_backup" cascade
[0m18:18:44.456466 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.000 seconds
[0m18:18:44.460463 [debug] [Thread-1 (]: On model.data_house.transform_messages: Close
[0m18:18:44.462467 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '25e6f3f5-9b81-449e-b41f-818e375b30ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001907C0EA390>]}
[0m18:18:44.465462 [info ] [Thread-1 (]: 2 of 3 OK created sql view model public.transform_messages ..................... [[32mCREATE VIEW[0m in 0.44s]
[0m18:18:44.469464 [debug] [Thread-1 (]: Finished running node model.data_house.transform_messages
[0m18:18:44.471470 [debug] [Thread-1 (]: Began running node model.data_house.my_second_dbt_model
[0m18:18:44.472467 [info ] [Thread-1 (]: 3 of 3 START sql view model public.my_second_dbt_model ......................... [RUN]
[0m18:18:44.475462 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_house.transform_messages, now model.data_house.my_second_dbt_model)
[0m18:18:44.477467 [debug] [Thread-1 (]: Began compiling node model.data_house.my_second_dbt_model
[0m18:18:44.490466 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_house.my_second_dbt_model"
[0m18:18:44.492470 [debug] [Thread-1 (]: Began executing node model.data_house.my_second_dbt_model
[0m18:18:44.509461 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_house.my_second_dbt_model"
[0m18:18:44.512466 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m18:18:44.514463 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: BEGIN
[0m18:18:44.527462 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:18:44.680466 [debug] [Thread-1 (]: SQL status: BEGIN in 0.154 seconds
[0m18:18:44.682469 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m18:18:44.683464 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_second_dbt_model"} */

  create view "Data_house"."public"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "Data_house"."public"."my_first_dbt_model"
where id = 1
  );
[0m18:18:44.732466 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.047 seconds
[0m18:18:44.741461 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m18:18:44.743464 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_second_dbt_model"} */
alter table "Data_house"."public"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m18:18:44.745466 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:18:44.750463 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: COMMIT
[0m18:18:44.751463 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m18:18:44.753463 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: COMMIT
[0m18:18:44.756463 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m18:18:44.765469 [debug] [Thread-1 (]: Applying DROP to: "Data_house"."public"."my_second_dbt_model__dbt_backup"
[0m18:18:44.770460 [debug] [Thread-1 (]: Using postgres connection "model.data_house.my_second_dbt_model"
[0m18:18:44.771462 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "model.data_house.my_second_dbt_model"} */
drop view if exists "Data_house"."public"."my_second_dbt_model__dbt_backup" cascade
[0m18:18:44.773461 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.000 seconds
[0m18:18:44.778463 [debug] [Thread-1 (]: On model.data_house.my_second_dbt_model: Close
[0m18:18:44.779463 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '25e6f3f5-9b81-449e-b41f-818e375b30ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001907C0AD040>]}
[0m18:18:44.782464 [info ] [Thread-1 (]: 3 of 3 OK created sql view model public.my_second_dbt_model .................... [[32mCREATE VIEW[0m in 0.30s]
[0m18:18:44.784463 [debug] [Thread-1 (]: Finished running node model.data_house.my_second_dbt_model
[0m18:18:44.787461 [debug] [MainThread]: Using postgres connection "master"
[0m18:18:44.788460 [debug] [MainThread]: On master: BEGIN
[0m18:18:44.788460 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:18:44.861462 [debug] [MainThread]: SQL status: BEGIN in 0.072 seconds
[0m18:18:44.861462 [debug] [MainThread]: On master: COMMIT
[0m18:18:44.862466 [debug] [MainThread]: Using postgres connection "master"
[0m18:18:44.863463 [debug] [MainThread]: On master: COMMIT
[0m18:18:44.864464 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:18:44.865470 [debug] [MainThread]: On master: Close
[0m18:18:44.868507 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:18:44.870479 [debug] [MainThread]: Connection 'list_Data_house' was properly closed.
[0m18:18:44.871466 [debug] [MainThread]: Connection 'list_Data_house_public' was properly closed.
[0m18:18:44.872461 [debug] [MainThread]: Connection 'model.data_house.my_second_dbt_model' was properly closed.
[0m18:18:44.873457 [info ] [MainThread]: 
[0m18:18:44.874457 [info ] [MainThread]: Finished running 1 table model, 2 view models in 0 hours 0 minutes and 1.78 seconds (1.78s).
[0m18:18:44.877459 [debug] [MainThread]: Command end result
[0m18:18:44.945464 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\manifest.json
[0m18:18:44.950515 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\semantic_manifest.json
[0m18:18:44.960463 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\run_results.json
[0m18:18:44.961464 [info ] [MainThread]: 
[0m18:18:44.962463 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:18:44.964464 [info ] [MainThread]: 
[0m18:18:44.966462 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m18:18:44.969467 [debug] [MainThread]: Command `dbt run` succeeded at 18:18:44.968468 after 4.50 seconds
[0m18:18:44.969467 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000190772CC800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019079D81AC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001907963E9F0>]}
[0m18:18:44.970457 [debug] [MainThread]: Flushing usage events
[0m18:18:46.855163 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:19:42.488714 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000145D8F6CE90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000145D789EB70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000145D9315DC0>]}


============================== 18:19:42.495883 | 1a9ee920-432b-4e25-ac3f-5d1fa7b9a150 ==============================
[0m18:19:42.495883 [info ] [MainThread]: Running with dbt=1.9.2
[0m18:19:42.497716 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\Dagi\\Documents\\KAIM\\week-7\\Ethiopian-Medical-DataWarehouse\\data_house\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\Dagi\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt test', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m18:19:42.890712 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1a9ee920-432b-4e25-ac3f-5d1fa7b9a150', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000145D9B31F40>]}
[0m18:19:43.053711 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1a9ee920-432b-4e25-ac3f-5d1fa7b9a150', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000145D9D22EA0>]}
[0m18:19:43.055715 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m18:19:43.515712 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m18:19:43.874713 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:19:43.874713 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:19:43.987715 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1a9ee920-432b-4e25-ac3f-5d1fa7b9a150', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000145D9FD4890>]}
[0m18:19:44.170709 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\manifest.json
[0m18:19:44.180717 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\semantic_manifest.json
[0m18:19:46.089015 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1a9ee920-432b-4e25-ac3f-5d1fa7b9a150', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000145DB37D820>]}
[0m18:19:46.090014 [info ] [MainThread]: Found 3 models, 4 data tests, 1 source, 431 macros
[0m18:19:46.091014 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1a9ee920-432b-4e25-ac3f-5d1fa7b9a150', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000145DB332F00>]}
[0m18:19:46.094033 [info ] [MainThread]: 
[0m18:19:46.096018 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:19:46.097017 [info ] [MainThread]: 
[0m18:19:46.099013 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m18:19:46.115015 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Data_house_public'
[0m18:19:46.288014 [debug] [ThreadPool]: Using postgres connection "list_Data_house_public"
[0m18:19:46.288014 [debug] [ThreadPool]: On list_Data_house_public: BEGIN
[0m18:19:46.289015 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:19:46.564018 [debug] [ThreadPool]: SQL status: BEGIN in 0.275 seconds
[0m18:19:46.565019 [debug] [ThreadPool]: Using postgres connection "list_Data_house_public"
[0m18:19:46.566014 [debug] [ThreadPool]: On list_Data_house_public: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "connection_name": "list_Data_house_public"} */
select
      'Data_house' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'Data_house' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
    union all
    select
      'Data_house' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public'
  
[0m18:19:46.577011 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.010 seconds
[0m18:19:46.580009 [debug] [ThreadPool]: On list_Data_house_public: ROLLBACK
[0m18:19:46.581010 [debug] [ThreadPool]: On list_Data_house_public: Close
[0m18:19:46.595010 [debug] [MainThread]: Using postgres connection "master"
[0m18:19:46.596009 [debug] [MainThread]: On master: BEGIN
[0m18:19:46.596009 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:19:46.676014 [debug] [MainThread]: SQL status: BEGIN in 0.080 seconds
[0m18:19:46.677013 [debug] [MainThread]: Using postgres connection "master"
[0m18:19:46.678015 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m18:19:46.699015 [debug] [MainThread]: SQL status: SELECT 3 in 0.017 seconds
[0m18:19:46.702008 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1a9ee920-432b-4e25-ac3f-5d1fa7b9a150', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000145D9D6A690>]}
[0m18:19:46.703010 [debug] [MainThread]: On master: ROLLBACK
[0m18:19:46.704011 [debug] [MainThread]: Using postgres connection "master"
[0m18:19:46.704011 [debug] [MainThread]: On master: BEGIN
[0m18:19:46.705011 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m18:19:46.706014 [debug] [MainThread]: On master: COMMIT
[0m18:19:46.707011 [debug] [MainThread]: Using postgres connection "master"
[0m18:19:46.707011 [debug] [MainThread]: On master: COMMIT
[0m18:19:46.709013 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:19:46.709013 [debug] [MainThread]: On master: Close
[0m18:19:46.716015 [debug] [Thread-1 (]: Began running node test.data_house.not_null_my_first_dbt_model_id.5fb22c2710
[0m18:19:46.718014 [info ] [Thread-1 (]: 1 of 4 START test not_null_my_first_dbt_model_id ............................... [RUN]
[0m18:19:46.720014 [debug] [Thread-1 (]: Acquiring new postgres connection 'test.data_house.not_null_my_first_dbt_model_id.5fb22c2710'
[0m18:19:46.721014 [debug] [Thread-1 (]: Began compiling node test.data_house.not_null_my_first_dbt_model_id.5fb22c2710
[0m18:19:46.782011 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_house.not_null_my_first_dbt_model_id.5fb22c2710"
[0m18:19:46.893016 [debug] [Thread-1 (]: Began executing node test.data_house.not_null_my_first_dbt_model_id.5fb22c2710
[0m18:19:46.951015 [debug] [Thread-1 (]: Writing runtime sql for node "test.data_house.not_null_my_first_dbt_model_id.5fb22c2710"
[0m18:19:46.993267 [debug] [Thread-1 (]: Using postgres connection "test.data_house.not_null_my_first_dbt_model_id.5fb22c2710"
[0m18:19:46.994271 [debug] [Thread-1 (]: On test.data_house.not_null_my_first_dbt_model_id.5fb22c2710: BEGIN
[0m18:19:46.995270 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m18:19:47.061864 [debug] [Thread-1 (]: SQL status: BEGIN in 0.067 seconds
[0m18:19:47.063860 [debug] [Thread-1 (]: Using postgres connection "test.data_house.not_null_my_first_dbt_model_id.5fb22c2710"
[0m18:19:47.063860 [debug] [Thread-1 (]: On test.data_house.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "test.data_house.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "Data_house"."public"."my_first_dbt_model"
where id is null



      
    ) dbt_internal_test
[0m18:19:47.066863 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m18:19:47.073860 [debug] [Thread-1 (]: On test.data_house.not_null_my_first_dbt_model_id.5fb22c2710: ROLLBACK
[0m18:19:47.074858 [debug] [Thread-1 (]: On test.data_house.not_null_my_first_dbt_model_id.5fb22c2710: Close
[0m18:19:47.075859 [error] [Thread-1 (]: 1 of 4 FAIL 1 not_null_my_first_dbt_model_id ................................... [[31mFAIL 1[0m in 0.36s]
[0m18:19:47.078868 [debug] [Thread-1 (]: Finished running node test.data_house.not_null_my_first_dbt_model_id.5fb22c2710
[0m18:19:47.079869 [debug] [Thread-1 (]: Began running node test.data_house.not_null_my_second_dbt_model_id.151b76d778
[0m18:19:47.080862 [info ] [Thread-1 (]: 2 of 4 START test not_null_my_second_dbt_model_id .............................. [RUN]
[0m18:19:47.082867 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_house.not_null_my_first_dbt_model_id.5fb22c2710, now test.data_house.not_null_my_second_dbt_model_id.151b76d778)
[0m18:19:47.084868 [debug] [Thread-1 (]: Began compiling node test.data_house.not_null_my_second_dbt_model_id.151b76d778
[0m18:19:47.092859 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_house.not_null_my_second_dbt_model_id.151b76d778"
[0m18:19:47.101868 [debug] [Thread-1 (]: Began executing node test.data_house.not_null_my_second_dbt_model_id.151b76d778
[0m18:19:47.107859 [debug] [Thread-1 (]: Writing runtime sql for node "test.data_house.not_null_my_second_dbt_model_id.151b76d778"
[0m18:19:47.110864 [debug] [Thread-1 (]: Using postgres connection "test.data_house.not_null_my_second_dbt_model_id.151b76d778"
[0m18:19:47.115867 [debug] [Thread-1 (]: On test.data_house.not_null_my_second_dbt_model_id.151b76d778: BEGIN
[0m18:19:47.117561 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:19:47.209578 [debug] [Thread-1 (]: SQL status: BEGIN in 0.092 seconds
[0m18:19:47.210580 [debug] [Thread-1 (]: Using postgres connection "test.data_house.not_null_my_second_dbt_model_id.151b76d778"
[0m18:19:47.211581 [debug] [Thread-1 (]: On test.data_house.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "test.data_house.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "Data_house"."public"."my_second_dbt_model"
where id is null



      
    ) dbt_internal_test
[0m18:19:47.216579 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.003 seconds
[0m18:19:47.221585 [debug] [Thread-1 (]: On test.data_house.not_null_my_second_dbt_model_id.151b76d778: ROLLBACK
[0m18:19:47.223581 [debug] [Thread-1 (]: On test.data_house.not_null_my_second_dbt_model_id.151b76d778: Close
[0m18:19:47.225589 [info ] [Thread-1 (]: 2 of 4 PASS not_null_my_second_dbt_model_id .................................... [[32mPASS[0m in 0.14s]
[0m18:19:47.228586 [debug] [Thread-1 (]: Finished running node test.data_house.not_null_my_second_dbt_model_id.151b76d778
[0m18:19:47.230582 [debug] [Thread-1 (]: Began running node test.data_house.unique_my_first_dbt_model_id.16e066b321
[0m18:19:47.231580 [info ] [Thread-1 (]: 3 of 4 START test unique_my_first_dbt_model_id ................................. [RUN]
[0m18:19:47.233579 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_house.not_null_my_second_dbt_model_id.151b76d778, now test.data_house.unique_my_first_dbt_model_id.16e066b321)
[0m18:19:47.235581 [debug] [Thread-1 (]: Began compiling node test.data_house.unique_my_first_dbt_model_id.16e066b321
[0m18:19:47.266582 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_house.unique_my_first_dbt_model_id.16e066b321"
[0m18:19:47.416577 [debug] [Thread-1 (]: Began executing node test.data_house.unique_my_first_dbt_model_id.16e066b321
[0m18:19:47.422599 [debug] [Thread-1 (]: Writing runtime sql for node "test.data_house.unique_my_first_dbt_model_id.16e066b321"
[0m18:19:47.465581 [debug] [Thread-1 (]: Using postgres connection "test.data_house.unique_my_first_dbt_model_id.16e066b321"
[0m18:19:47.466578 [debug] [Thread-1 (]: On test.data_house.unique_my_first_dbt_model_id.16e066b321: BEGIN
[0m18:19:47.467581 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:19:47.540581 [debug] [Thread-1 (]: SQL status: BEGIN in 0.073 seconds
[0m18:19:47.541580 [debug] [Thread-1 (]: Using postgres connection "test.data_house.unique_my_first_dbt_model_id.16e066b321"
[0m18:19:47.541580 [debug] [Thread-1 (]: On test.data_house.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "test.data_house.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "Data_house"."public"."my_first_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m18:19:47.545584 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.003 seconds
[0m18:19:47.547577 [debug] [Thread-1 (]: On test.data_house.unique_my_first_dbt_model_id.16e066b321: ROLLBACK
[0m18:19:47.548579 [debug] [Thread-1 (]: On test.data_house.unique_my_first_dbt_model_id.16e066b321: Close
[0m18:19:47.550579 [info ] [Thread-1 (]: 3 of 4 PASS unique_my_first_dbt_model_id ....................................... [[32mPASS[0m in 0.32s]
[0m18:19:47.553577 [debug] [Thread-1 (]: Finished running node test.data_house.unique_my_first_dbt_model_id.16e066b321
[0m18:19:47.555577 [debug] [Thread-1 (]: Began running node test.data_house.unique_my_second_dbt_model_id.57a0f8c493
[0m18:19:47.557580 [info ] [Thread-1 (]: 4 of 4 START test unique_my_second_dbt_model_id ................................ [RUN]
[0m18:19:47.559582 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_house.unique_my_first_dbt_model_id.16e066b321, now test.data_house.unique_my_second_dbt_model_id.57a0f8c493)
[0m18:19:47.561580 [debug] [Thread-1 (]: Began compiling node test.data_house.unique_my_second_dbt_model_id.57a0f8c493
[0m18:19:47.575582 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_house.unique_my_second_dbt_model_id.57a0f8c493"
[0m18:19:47.577588 [debug] [Thread-1 (]: Began executing node test.data_house.unique_my_second_dbt_model_id.57a0f8c493
[0m18:19:47.586575 [debug] [Thread-1 (]: Writing runtime sql for node "test.data_house.unique_my_second_dbt_model_id.57a0f8c493"
[0m18:19:47.616584 [debug] [Thread-1 (]: Using postgres connection "test.data_house.unique_my_second_dbt_model_id.57a0f8c493"
[0m18:19:47.619586 [debug] [Thread-1 (]: On test.data_house.unique_my_second_dbt_model_id.57a0f8c493: BEGIN
[0m18:19:47.620582 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:19:47.692577 [debug] [Thread-1 (]: SQL status: BEGIN in 0.072 seconds
[0m18:19:47.693580 [debug] [Thread-1 (]: Using postgres connection "test.data_house.unique_my_second_dbt_model_id.57a0f8c493"
[0m18:19:47.694578 [debug] [Thread-1 (]: On test.data_house.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "test.data_house.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "Data_house"."public"."my_second_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m18:19:47.697579 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.003 seconds
[0m18:19:47.700578 [debug] [Thread-1 (]: On test.data_house.unique_my_second_dbt_model_id.57a0f8c493: ROLLBACK
[0m18:19:47.701577 [debug] [Thread-1 (]: On test.data_house.unique_my_second_dbt_model_id.57a0f8c493: Close
[0m18:19:47.703579 [info ] [Thread-1 (]: 4 of 4 PASS unique_my_second_dbt_model_id ...................................... [[32mPASS[0m in 0.14s]
[0m18:19:47.706577 [debug] [Thread-1 (]: Finished running node test.data_house.unique_my_second_dbt_model_id.57a0f8c493
[0m18:19:47.709578 [debug] [MainThread]: Using postgres connection "master"
[0m18:19:47.709578 [debug] [MainThread]: On master: BEGIN
[0m18:19:47.710578 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:19:47.785583 [debug] [MainThread]: SQL status: BEGIN in 0.075 seconds
[0m18:19:47.786579 [debug] [MainThread]: On master: COMMIT
[0m18:19:47.787575 [debug] [MainThread]: Using postgres connection "master"
[0m18:19:47.788576 [debug] [MainThread]: On master: COMMIT
[0m18:19:47.789576 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:19:47.791575 [debug] [MainThread]: On master: Close
[0m18:19:47.792575 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:19:47.793580 [debug] [MainThread]: Connection 'list_Data_house_public' was properly closed.
[0m18:19:47.794583 [debug] [MainThread]: Connection 'test.data_house.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
[0m18:19:47.796588 [info ] [MainThread]: 
[0m18:19:47.797582 [info ] [MainThread]: Finished running 4 data tests in 0 hours 0 minutes and 1.70 seconds (1.70s).
[0m18:19:47.801584 [debug] [MainThread]: Command end result
[0m18:19:47.846591 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\manifest.json
[0m18:19:47.852584 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\semantic_manifest.json
[0m18:19:47.864577 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\run_results.json
[0m18:19:47.865580 [info ] [MainThread]: 
[0m18:19:47.866580 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m18:19:47.867577 [info ] [MainThread]: 
[0m18:19:47.869576 [error] [MainThread]: [31mFailure in test not_null_my_first_dbt_model_id (models\example\schema.yml)[0m
[0m18:19:47.870579 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m18:19:47.871576 [info ] [MainThread]: 
[0m18:19:47.872581 [info ] [MainThread]:   compiled code at target\compiled\data_house\models\example\schema.yml\not_null_my_first_dbt_model_id.sql
[0m18:19:47.874581 [info ] [MainThread]: 
[0m18:19:47.875583 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m18:19:47.878578 [debug] [MainThread]: Command `dbt test` failed at 18:19:47.878578 after 5.98 seconds
[0m18:19:47.879578 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000145D789EB70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000145D99D1B50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000145D99D3710>]}
[0m18:19:47.879578 [debug] [MainThread]: Flushing usage events
[0m18:19:49.905917 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:21:12.709526 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014FC30447A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014FC28B3B30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014FC2DED370>]}


============================== 18:21:12.719254 | 9b450fda-f052-4846-8e12-bbd9f4699406 ==============================
[0m18:21:12.719254 [info ] [MainThread]: Running with dbt=1.9.2
[0m18:21:12.722240 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\Dagi\\Documents\\KAIM\\week-7\\Ethiopian-Medical-DataWarehouse\\data_house\\logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\Dagi\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt test', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m18:21:13.096454 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9b450fda-f052-4846-8e12-bbd9f4699406', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014FC3506ED0>]}
[0m18:21:13.194455 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9b450fda-f052-4846-8e12-bbd9f4699406', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014FC36D0D10>]}
[0m18:21:13.196456 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m18:21:13.576453 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m18:21:13.938415 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:21:13.938415 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:21:14.054414 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9b450fda-f052-4846-8e12-bbd9f4699406', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014FC38149B0>]}
[0m18:21:14.209423 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\manifest.json
[0m18:21:14.218417 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\semantic_manifest.json
[0m18:21:14.298418 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9b450fda-f052-4846-8e12-bbd9f4699406', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014FC4D0DC40>]}
[0m18:21:14.299415 [info ] [MainThread]: Found 3 models, 4 data tests, 1 source, 431 macros
[0m18:21:14.300416 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9b450fda-f052-4846-8e12-bbd9f4699406', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014FC39601D0>]}
[0m18:21:14.303408 [info ] [MainThread]: 
[0m18:21:14.304414 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:21:14.397591 [info ] [MainThread]: 
[0m18:21:14.399590 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m18:21:14.405611 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Data_house_public'
[0m18:21:14.547256 [debug] [ThreadPool]: Using postgres connection "list_Data_house_public"
[0m18:21:14.547256 [debug] [ThreadPool]: On list_Data_house_public: BEGIN
[0m18:21:14.548257 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:21:14.703748 [debug] [ThreadPool]: SQL status: BEGIN in 0.155 seconds
[0m18:21:14.704772 [debug] [ThreadPool]: Using postgres connection "list_Data_house_public"
[0m18:21:14.704772 [debug] [ThreadPool]: On list_Data_house_public: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "connection_name": "list_Data_house_public"} */
select
      'Data_house' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'Data_house' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
    union all
    select
      'Data_house' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public'
  
[0m18:21:14.717817 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.012 seconds
[0m18:21:14.720842 [debug] [ThreadPool]: On list_Data_house_public: ROLLBACK
[0m18:21:14.720842 [debug] [ThreadPool]: On list_Data_house_public: Close
[0m18:21:14.732822 [debug] [MainThread]: Using postgres connection "master"
[0m18:21:14.732822 [debug] [MainThread]: On master: BEGIN
[0m18:21:14.733823 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:21:14.794423 [debug] [MainThread]: SQL status: BEGIN in 0.060 seconds
[0m18:21:14.795433 [debug] [MainThread]: Using postgres connection "master"
[0m18:21:14.795433 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m18:21:14.814453 [debug] [MainThread]: SQL status: SELECT 3 in 0.018 seconds
[0m18:21:14.817424 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9b450fda-f052-4846-8e12-bbd9f4699406', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014FC37EA5A0>]}
[0m18:21:14.818423 [debug] [MainThread]: On master: ROLLBACK
[0m18:21:14.818423 [debug] [MainThread]: Using postgres connection "master"
[0m18:21:14.819429 [debug] [MainThread]: On master: BEGIN
[0m18:21:14.820429 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m18:21:14.821429 [debug] [MainThread]: On master: COMMIT
[0m18:21:14.821429 [debug] [MainThread]: Using postgres connection "master"
[0m18:21:14.822431 [debug] [MainThread]: On master: COMMIT
[0m18:21:14.823430 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:21:14.824428 [debug] [MainThread]: On master: Close
[0m18:21:14.828426 [debug] [Thread-1 (]: Began running node test.data_house.not_null_my_first_dbt_model_id.5fb22c2710
[0m18:21:14.830424 [info ] [Thread-1 (]: 1 of 4 START test not_null_my_first_dbt_model_id ............................... [RUN]
[0m18:21:14.832425 [debug] [Thread-1 (]: Acquiring new postgres connection 'test.data_house.not_null_my_first_dbt_model_id.5fb22c2710'
[0m18:21:14.833430 [debug] [Thread-1 (]: Began compiling node test.data_house.not_null_my_first_dbt_model_id.5fb22c2710
[0m18:21:14.869446 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_house.not_null_my_first_dbt_model_id.5fb22c2710"
[0m18:21:14.871434 [debug] [Thread-1 (]: Began executing node test.data_house.not_null_my_first_dbt_model_id.5fb22c2710
[0m18:21:14.897448 [debug] [Thread-1 (]: Writing runtime sql for node "test.data_house.not_null_my_first_dbt_model_id.5fb22c2710"
[0m18:21:14.898454 [debug] [Thread-1 (]: Using postgres connection "test.data_house.not_null_my_first_dbt_model_id.5fb22c2710"
[0m18:21:14.900452 [debug] [Thread-1 (]: On test.data_house.not_null_my_first_dbt_model_id.5fb22c2710: BEGIN
[0m18:21:14.901448 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m18:21:15.103073 [debug] [Thread-1 (]: SQL status: BEGIN in 0.202 seconds
[0m18:21:15.104090 [debug] [Thread-1 (]: Using postgres connection "test.data_house.not_null_my_first_dbt_model_id.5fb22c2710"
[0m18:21:15.105090 [debug] [Thread-1 (]: On test.data_house.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "test.data_house.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "Data_house"."public"."my_first_dbt_model"
where id is null



      
    ) dbt_internal_test
[0m18:21:15.108079 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m18:21:15.113068 [debug] [Thread-1 (]: On test.data_house.not_null_my_first_dbt_model_id.5fb22c2710: ROLLBACK
[0m18:21:15.114071 [debug] [Thread-1 (]: On test.data_house.not_null_my_first_dbt_model_id.5fb22c2710: Close
[0m18:21:15.115091 [info ] [Thread-1 (]: 1 of 4 PASS not_null_my_first_dbt_model_id ..................................... [[32mPASS[0m in 0.28s]
[0m18:21:15.117065 [debug] [Thread-1 (]: Finished running node test.data_house.not_null_my_first_dbt_model_id.5fb22c2710
[0m18:21:15.118071 [debug] [Thread-1 (]: Began running node test.data_house.not_null_my_second_dbt_model_id.151b76d778
[0m18:21:15.119073 [info ] [Thread-1 (]: 2 of 4 START test not_null_my_second_dbt_model_id .............................. [RUN]
[0m18:21:15.120063 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_house.not_null_my_first_dbt_model_id.5fb22c2710, now test.data_house.not_null_my_second_dbt_model_id.151b76d778)
[0m18:21:15.121071 [debug] [Thread-1 (]: Began compiling node test.data_house.not_null_my_second_dbt_model_id.151b76d778
[0m18:21:15.127068 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_house.not_null_my_second_dbt_model_id.151b76d778"
[0m18:21:15.146801 [debug] [Thread-1 (]: Began executing node test.data_house.not_null_my_second_dbt_model_id.151b76d778
[0m18:21:15.154798 [debug] [Thread-1 (]: Writing runtime sql for node "test.data_house.not_null_my_second_dbt_model_id.151b76d778"
[0m18:21:15.160879 [debug] [Thread-1 (]: Using postgres connection "test.data_house.not_null_my_second_dbt_model_id.151b76d778"
[0m18:21:15.161806 [debug] [Thread-1 (]: On test.data_house.not_null_my_second_dbt_model_id.151b76d778: BEGIN
[0m18:21:15.162814 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:21:15.234794 [debug] [Thread-1 (]: SQL status: BEGIN in 0.072 seconds
[0m18:21:15.235796 [debug] [Thread-1 (]: Using postgres connection "test.data_house.not_null_my_second_dbt_model_id.151b76d778"
[0m18:21:15.236795 [debug] [Thread-1 (]: On test.data_house.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "test.data_house.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "Data_house"."public"."my_second_dbt_model"
where id is null



      
    ) dbt_internal_test
[0m18:21:15.239796 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m18:21:15.242796 [debug] [Thread-1 (]: On test.data_house.not_null_my_second_dbt_model_id.151b76d778: ROLLBACK
[0m18:21:15.243795 [debug] [Thread-1 (]: On test.data_house.not_null_my_second_dbt_model_id.151b76d778: Close
[0m18:21:15.244797 [info ] [Thread-1 (]: 2 of 4 PASS not_null_my_second_dbt_model_id .................................... [[32mPASS[0m in 0.12s]
[0m18:21:15.247796 [debug] [Thread-1 (]: Finished running node test.data_house.not_null_my_second_dbt_model_id.151b76d778
[0m18:21:15.248798 [debug] [Thread-1 (]: Began running node test.data_house.unique_my_first_dbt_model_id.16e066b321
[0m18:21:15.249797 [info ] [Thread-1 (]: 3 of 4 START test unique_my_first_dbt_model_id ................................. [RUN]
[0m18:21:15.250803 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_house.not_null_my_second_dbt_model_id.151b76d778, now test.data_house.unique_my_first_dbt_model_id.16e066b321)
[0m18:21:15.251800 [debug] [Thread-1 (]: Began compiling node test.data_house.unique_my_first_dbt_model_id.16e066b321
[0m18:21:15.264797 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_house.unique_my_first_dbt_model_id.16e066b321"
[0m18:21:15.268872 [debug] [Thread-1 (]: Began executing node test.data_house.unique_my_first_dbt_model_id.16e066b321
[0m18:21:15.274805 [debug] [Thread-1 (]: Writing runtime sql for node "test.data_house.unique_my_first_dbt_model_id.16e066b321"
[0m18:21:15.279796 [debug] [Thread-1 (]: Using postgres connection "test.data_house.unique_my_first_dbt_model_id.16e066b321"
[0m18:21:15.280802 [debug] [Thread-1 (]: On test.data_house.unique_my_first_dbt_model_id.16e066b321: BEGIN
[0m18:21:15.281799 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:21:15.357796 [debug] [Thread-1 (]: SQL status: BEGIN in 0.077 seconds
[0m18:21:15.358805 [debug] [Thread-1 (]: Using postgres connection "test.data_house.unique_my_first_dbt_model_id.16e066b321"
[0m18:21:15.359795 [debug] [Thread-1 (]: On test.data_house.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "test.data_house.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "Data_house"."public"."my_first_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m18:21:15.362794 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m18:21:15.364791 [debug] [Thread-1 (]: On test.data_house.unique_my_first_dbt_model_id.16e066b321: ROLLBACK
[0m18:21:15.365791 [debug] [Thread-1 (]: On test.data_house.unique_my_first_dbt_model_id.16e066b321: Close
[0m18:21:15.367796 [info ] [Thread-1 (]: 3 of 4 PASS unique_my_first_dbt_model_id ....................................... [[32mPASS[0m in 0.12s]
[0m18:21:15.369798 [debug] [Thread-1 (]: Finished running node test.data_house.unique_my_first_dbt_model_id.16e066b321
[0m18:21:15.371797 [debug] [Thread-1 (]: Began running node test.data_house.unique_my_second_dbt_model_id.57a0f8c493
[0m18:21:15.372795 [info ] [Thread-1 (]: 4 of 4 START test unique_my_second_dbt_model_id ................................ [RUN]
[0m18:21:15.374797 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_house.unique_my_first_dbt_model_id.16e066b321, now test.data_house.unique_my_second_dbt_model_id.57a0f8c493)
[0m18:21:15.376800 [debug] [Thread-1 (]: Began compiling node test.data_house.unique_my_second_dbt_model_id.57a0f8c493
[0m18:21:15.388802 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_house.unique_my_second_dbt_model_id.57a0f8c493"
[0m18:21:15.391799 [debug] [Thread-1 (]: Began executing node test.data_house.unique_my_second_dbt_model_id.57a0f8c493
[0m18:21:15.398801 [debug] [Thread-1 (]: Writing runtime sql for node "test.data_house.unique_my_second_dbt_model_id.57a0f8c493"
[0m18:21:15.400799 [debug] [Thread-1 (]: Using postgres connection "test.data_house.unique_my_second_dbt_model_id.57a0f8c493"
[0m18:21:15.401803 [debug] [Thread-1 (]: On test.data_house.unique_my_second_dbt_model_id.57a0f8c493: BEGIN
[0m18:21:15.401803 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:21:15.505798 [debug] [Thread-1 (]: SQL status: BEGIN in 0.104 seconds
[0m18:21:15.506795 [debug] [Thread-1 (]: Using postgres connection "test.data_house.unique_my_second_dbt_model_id.57a0f8c493"
[0m18:21:15.507801 [debug] [Thread-1 (]: On test.data_house.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "node_id": "test.data_house.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "Data_house"."public"."my_second_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m18:21:15.510794 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m18:21:15.513794 [debug] [Thread-1 (]: On test.data_house.unique_my_second_dbt_model_id.57a0f8c493: ROLLBACK
[0m18:21:15.514793 [debug] [Thread-1 (]: On test.data_house.unique_my_second_dbt_model_id.57a0f8c493: Close
[0m18:21:15.515794 [info ] [Thread-1 (]: 4 of 4 PASS unique_my_second_dbt_model_id ...................................... [[32mPASS[0m in 0.14s]
[0m18:21:15.518799 [debug] [Thread-1 (]: Finished running node test.data_house.unique_my_second_dbt_model_id.57a0f8c493
[0m18:21:15.520797 [debug] [MainThread]: Using postgres connection "master"
[0m18:21:15.521797 [debug] [MainThread]: On master: BEGIN
[0m18:21:15.521797 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:21:15.598795 [debug] [MainThread]: SQL status: BEGIN in 0.077 seconds
[0m18:21:15.599799 [debug] [MainThread]: On master: COMMIT
[0m18:21:15.599799 [debug] [MainThread]: Using postgres connection "master"
[0m18:21:15.600791 [debug] [MainThread]: On master: COMMIT
[0m18:21:15.601793 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:21:15.601793 [debug] [MainThread]: On master: Close
[0m18:21:15.602791 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:21:15.603798 [debug] [MainThread]: Connection 'list_Data_house_public' was properly closed.
[0m18:21:15.604802 [debug] [MainThread]: Connection 'test.data_house.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
[0m18:21:15.605799 [info ] [MainThread]: 
[0m18:21:15.607800 [info ] [MainThread]: Finished running 4 data tests in 0 hours 0 minutes and 1.21 seconds (1.21s).
[0m18:21:15.610798 [debug] [MainThread]: Command end result
[0m18:21:15.652792 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\manifest.json
[0m18:21:15.657803 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\semantic_manifest.json
[0m18:21:15.678811 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\run_results.json
[0m18:21:15.679809 [info ] [MainThread]: 
[0m18:21:15.680794 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:21:15.681796 [info ] [MainThread]: 
[0m18:21:15.682798 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m18:21:15.684798 [debug] [MainThread]: Command `dbt test` succeeded at 18:21:15.684798 after 3.63 seconds
[0m18:21:15.685797 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014FC28B3B30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014FC3275E50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014FBF0EC950>]}
[0m18:21:15.686797 [debug] [MainThread]: Flushing usage events
[0m18:21:17.012210 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:22:10.425684 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016FE90E5160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016FE90E7A40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016FE9B5C170>]}


============================== 18:22:10.516690 | deecdb0b-c4eb-4cb6-a2cf-8968fce291d7 ==============================
[0m18:22:10.516690 [info ] [MainThread]: Running with dbt=1.9.2
[0m18:22:10.542694 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Dagi\\.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'C:\\Users\\Dagi\\Documents\\KAIM\\week-7\\Ethiopian-Medical-DataWarehouse\\data_house\\logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt docs generate', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m18:22:12.513908 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'deecdb0b-c4eb-4cb6-a2cf-8968fce291d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016FE9F3E570>]}
[0m18:22:12.655196 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'deecdb0b-c4eb-4cb6-a2cf-8968fce291d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016FE79EDAC0>]}
[0m18:22:12.657195 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m18:22:13.501196 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m18:22:14.034194 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:22:14.035196 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:22:14.126194 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'deecdb0b-c4eb-4cb6-a2cf-8968fce291d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016FEA02D8E0>]}
[0m18:22:14.558507 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'deecdb0b-c4eb-4cb6-a2cf-8968fce291d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016FEB378AA0>]}
[0m18:22:14.559515 [info ] [MainThread]: Found 3 models, 4 data tests, 1 source, 431 macros
[0m18:22:14.561533 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'deecdb0b-c4eb-4cb6-a2cf-8968fce291d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016FEB351DC0>]}
[0m18:22:14.568507 [info ] [MainThread]: 
[0m18:22:14.570510 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:22:14.578510 [info ] [MainThread]: 
[0m18:22:14.584509 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m18:22:14.620511 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Data_house_public'
[0m18:22:15.836917 [debug] [ThreadPool]: Using postgres connection "list_Data_house_public"
[0m18:22:15.852923 [debug] [ThreadPool]: On list_Data_house_public: BEGIN
[0m18:22:15.853920 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:22:17.531398 [debug] [ThreadPool]: SQL status: BEGIN in 1.678 seconds
[0m18:22:17.533401 [debug] [ThreadPool]: Using postgres connection "list_Data_house_public"
[0m18:22:17.533401 [debug] [ThreadPool]: On list_Data_house_public: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "connection_name": "list_Data_house_public"} */
select
      'Data_house' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'Data_house' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
    union all
    select
      'Data_house' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public'
  
[0m18:22:17.701404 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.166 seconds
[0m18:22:17.705411 [debug] [ThreadPool]: On list_Data_house_public: ROLLBACK
[0m18:22:17.706404 [debug] [ThreadPool]: On list_Data_house_public: Close
[0m18:22:17.771403 [debug] [MainThread]: Using postgres connection "master"
[0m18:22:17.772408 [debug] [MainThread]: On master: BEGIN
[0m18:22:17.773406 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:22:18.482135 [debug] [MainThread]: SQL status: BEGIN in 0.709 seconds
[0m18:22:18.483154 [debug] [MainThread]: Using postgres connection "master"
[0m18:22:18.484155 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m18:22:18.648278 [debug] [MainThread]: SQL status: SELECT 3 in 0.163 seconds
[0m18:22:18.658275 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'deecdb0b-c4eb-4cb6-a2cf-8968fce291d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016FEA0781D0>]}
[0m18:22:18.659273 [debug] [MainThread]: On master: ROLLBACK
[0m18:22:18.660273 [debug] [MainThread]: On master: Close
[0m18:22:18.839798 [debug] [Thread-1 (]: Began running node model.data_house.my_first_dbt_model
[0m18:22:18.842793 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.data_house.my_first_dbt_model'
[0m18:22:18.844835 [debug] [Thread-1 (]: Began compiling node model.data_house.my_first_dbt_model
[0m18:22:18.877793 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_house.my_first_dbt_model"
[0m18:22:18.879794 [debug] [Thread-1 (]: Began executing node model.data_house.my_first_dbt_model
[0m18:22:18.882780 [debug] [Thread-1 (]: Finished running node model.data_house.my_first_dbt_model
[0m18:22:18.882780 [debug] [Thread-1 (]: Began running node model.data_house.transform_messages
[0m18:22:18.884773 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_house.my_first_dbt_model, now model.data_house.transform_messages)
[0m18:22:18.885770 [debug] [Thread-1 (]: Began compiling node model.data_house.transform_messages
[0m18:22:18.890793 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_house.transform_messages"
[0m18:22:18.892784 [debug] [Thread-1 (]: Began executing node model.data_house.transform_messages
[0m18:22:18.894796 [debug] [Thread-1 (]: Finished running node model.data_house.transform_messages
[0m18:22:18.895793 [debug] [Thread-1 (]: Began running node model.data_house.my_second_dbt_model
[0m18:22:18.896794 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_house.transform_messages, now model.data_house.my_second_dbt_model)
[0m18:22:18.897793 [debug] [Thread-1 (]: Began compiling node model.data_house.my_second_dbt_model
[0m18:22:18.902793 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_house.my_second_dbt_model"
[0m18:22:18.904773 [debug] [Thread-1 (]: Began executing node model.data_house.my_second_dbt_model
[0m18:22:18.906778 [debug] [Thread-1 (]: Finished running node model.data_house.my_second_dbt_model
[0m18:22:18.907775 [debug] [Thread-1 (]: Began running node test.data_house.not_null_my_first_dbt_model_id.5fb22c2710
[0m18:22:18.908776 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_house.my_second_dbt_model, now test.data_house.not_null_my_first_dbt_model_id.5fb22c2710)
[0m18:22:18.909784 [debug] [Thread-1 (]: Began compiling node test.data_house.not_null_my_first_dbt_model_id.5fb22c2710
[0m18:22:18.931774 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_house.not_null_my_first_dbt_model_id.5fb22c2710"
[0m18:22:18.933781 [debug] [Thread-1 (]: Began executing node test.data_house.not_null_my_first_dbt_model_id.5fb22c2710
[0m18:22:18.934778 [debug] [Thread-1 (]: Finished running node test.data_house.not_null_my_first_dbt_model_id.5fb22c2710
[0m18:22:18.936775 [debug] [Thread-1 (]: Began running node test.data_house.unique_my_first_dbt_model_id.16e066b321
[0m18:22:18.938779 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_house.not_null_my_first_dbt_model_id.5fb22c2710, now test.data_house.unique_my_first_dbt_model_id.16e066b321)
[0m18:22:18.939776 [debug] [Thread-1 (]: Began compiling node test.data_house.unique_my_first_dbt_model_id.16e066b321
[0m18:22:18.948775 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_house.unique_my_first_dbt_model_id.16e066b321"
[0m18:22:18.950783 [debug] [Thread-1 (]: Began executing node test.data_house.unique_my_first_dbt_model_id.16e066b321
[0m18:22:18.951778 [debug] [Thread-1 (]: Finished running node test.data_house.unique_my_first_dbt_model_id.16e066b321
[0m18:22:18.952780 [debug] [Thread-1 (]: Began running node test.data_house.not_null_my_second_dbt_model_id.151b76d778
[0m18:22:18.954780 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_house.unique_my_first_dbt_model_id.16e066b321, now test.data_house.not_null_my_second_dbt_model_id.151b76d778)
[0m18:22:18.954780 [debug] [Thread-1 (]: Began compiling node test.data_house.not_null_my_second_dbt_model_id.151b76d778
[0m18:22:18.961778 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_house.not_null_my_second_dbt_model_id.151b76d778"
[0m18:22:18.963782 [debug] [Thread-1 (]: Began executing node test.data_house.not_null_my_second_dbt_model_id.151b76d778
[0m18:22:18.964776 [debug] [Thread-1 (]: Finished running node test.data_house.not_null_my_second_dbt_model_id.151b76d778
[0m18:22:18.965776 [debug] [Thread-1 (]: Began running node test.data_house.unique_my_second_dbt_model_id.57a0f8c493
[0m18:22:18.966775 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_house.not_null_my_second_dbt_model_id.151b76d778, now test.data_house.unique_my_second_dbt_model_id.57a0f8c493)
[0m18:22:18.968775 [debug] [Thread-1 (]: Began compiling node test.data_house.unique_my_second_dbt_model_id.57a0f8c493
[0m18:22:18.975774 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_house.unique_my_second_dbt_model_id.57a0f8c493"
[0m18:22:18.977780 [debug] [Thread-1 (]: Began executing node test.data_house.unique_my_second_dbt_model_id.57a0f8c493
[0m18:22:18.980771 [debug] [Thread-1 (]: Finished running node test.data_house.unique_my_second_dbt_model_id.57a0f8c493
[0m18:22:18.982769 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:22:18.983770 [debug] [MainThread]: Connection 'list_Data_house_public' was properly closed.
[0m18:22:18.983770 [debug] [MainThread]: Connection 'test.data_house.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
[0m18:22:18.991776 [debug] [MainThread]: Command end result
[0m18:22:19.161773 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\manifest.json
[0m18:22:19.188776 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\semantic_manifest.json
[0m18:22:19.198770 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\run_results.json
[0m18:22:27.508968 [debug] [MainThread]: Acquiring new postgres connection 'generate_catalog'
[0m18:22:27.512966 [info ] [MainThread]: Building catalog
[0m18:22:27.556952 [debug] [ThreadPool]: Acquiring new postgres connection 'Data_house.information_schema'
[0m18:22:27.568945 [debug] [ThreadPool]: Using postgres connection "Data_house.information_schema"
[0m18:22:27.569947 [debug] [ThreadPool]: On Data_house.information_schema: BEGIN
[0m18:22:27.569947 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:22:27.657953 [debug] [ThreadPool]: SQL status: BEGIN in 0.087 seconds
[0m18:22:27.658950 [debug] [ThreadPool]: Using postgres connection "Data_house.information_schema"
[0m18:22:27.659950 [debug] [ThreadPool]: On Data_house.information_schema: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "data_house", "target_name": "dev", "connection_name": "Data_house.information_schema"} */

    
    

    select
        'Data_house' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            when 'm' then 'MATERIALIZED VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
    where ((upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('telegram_messages')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('my_second_dbt_model')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('transform_messages')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('my_first_dbt_model')))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence in ('p', 'u') -- [p]ermanent table or [u]nlogged table. Exclude [t]emporary tables
      and tbl.relkind in ('r', 'v', 'f', 'p', 'm') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table, [m]aterialized view. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
[0m18:22:28.001268 [debug] [ThreadPool]: SQL status: SELECT 23 in 0.340 seconds
[0m18:22:28.056267 [debug] [ThreadPool]: On Data_house.information_schema: ROLLBACK
[0m18:22:28.057266 [debug] [ThreadPool]: On Data_house.information_schema: Close
[0m18:22:28.080266 [debug] [MainThread]: Wrote artifact CatalogArtifact to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\catalog.json
[0m18:22:28.144268 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\manifest.json
[0m18:22:28.147267 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\semantic_manifest.json
[0m18:22:28.148267 [info ] [MainThread]: Catalog written to C:\Users\Dagi\Documents\KAIM\week-7\Ethiopian-Medical-DataWarehouse\data_house\target\catalog.json
[0m18:22:28.150270 [debug] [MainThread]: Command `dbt docs generate` succeeded at 18:22:28.150270 after 18.96 seconds
[0m18:22:28.151265 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m18:22:28.151265 [debug] [MainThread]: Connection 'Data_house.information_schema' was properly closed.
[0m18:22:28.152264 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016FE95F68A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016FE97C6D80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016FE97C6B70>]}
[0m18:22:28.153265 [debug] [MainThread]: Flushing usage events
[0m18:22:30.522523 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:25:38.015077 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000136B85C9EE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000136B85CAF30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000136B7BCE4B0>]}


============================== 18:25:38.022038 | a8d7232f-ce66-4be5-8e9d-14f4bf48ec14 ==============================
[0m18:25:38.022038 [info ] [MainThread]: Running with dbt=1.9.2
[0m18:25:38.024042 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Dagi\\.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'C:\\Users\\Dagi\\Documents\\KAIM\\week-7\\Ethiopian-Medical-DataWarehouse\\data_house\\logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt docs serve', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m18:25:38.355704 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a8d7232f-ce66-4be5-8e9d-14f4bf48ec14', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000136B8E2BF80>]}
[0m18:25:38.453684 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a8d7232f-ce66-4be5-8e9d-14f4bf48ec14', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000136B605F530>]}
